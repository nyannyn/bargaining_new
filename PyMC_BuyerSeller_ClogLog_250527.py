#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
è²·è³£é›™æ–¹äº’å‹•æ¥å—è¡Œç‚ºæ¨¡å‹ - éˆæ¥å‡½æ•¸æ¯”è¼ƒç ”ç©¶
=============================================

é€™å€‹ç¨‹å¼å¯¦ç¾äº†ä¸€å€‹è¤‡é›œçš„è²æ°çµ±è¨ˆæ¨¡å‹ï¼Œç”¨æ–¼æ¯”è¼ƒå…©ç¨®ä¸åŒçš„éˆæ¥å‡½æ•¸ä¾†å»ºæ¨¡è³£å®¶æ¥å—æ±ºç­–ï¼ˆSAï¼‰çš„åèª¤ï¼š

1. **æ¨¡æ“¬è³‡æ–™**ï¼šç”Ÿæˆè²·è³£é›™æ–¹äº’å‹•è³‡æ–™ï¼ŒåŒ…å«è³£å®¶å›æ‡‰æ™‚é–“(SRT)å’Œæ¥å—è¡Œç‚º(SA)
2. **å…©ç¨®éˆæ¥å‡½æ•¸æ¯”è¼ƒ**ï¼š
   - **Fraction link**: P(a=1|s,x) = s_ij / (Î´_ij + Îº_ij)
   - **Complementary Log-log link**: P(a=1|s,x) = 1 - (c_ij/(c_ij + Ï„_ij*s_ij))^q
3. **æ¨¡å‹æ¯”è¼ƒ**ï¼šæ¯”è¼ƒå…©ç¨®ä¸åŒéˆæ¥å‡½æ•¸çš„å»ºæ¨¡æ•ˆæœ
4. **æ¨è«–æ–¹æ³•**ï¼šä½¿ç”¨ NUTS MCMC å’Œ ADVI è®Šåˆ†æ¨è«–é€²è¡Œåƒæ•¸ä¼°è¨ˆ

Fraction link æ ¸å¿ƒå…¬å¼ï¼š
- Îº_ij = exp(x_ij^T * Î¸)  
- Î´_ij = Î³ * exp(-X_ij^T * Î²)
- æ¥å—æ©Ÿç‡ï¼šP(a_ij = 1 | s_ij) = s_ij / (Î´_ij + Îº_ij)

Complementary Log-log link æ ¸å¿ƒå…¬å¼ï¼š
- æ¥å—æ©Ÿç‡ï¼šP(a_ij = 1 | s_ij, x_ij) = 1 - (c_ij / (c_ij + Ï„_ij * s_ij))^q
- é€Ÿç‡åƒæ•¸ï¼šc_ij = Î³ * exp(-X_ij^T * Î²)  
- æ™‚é–“ä¿‚æ•¸ï¼šÏ„_ij = exp(x_ij^T * Î¸)

PyMC æœ€ä½³å¯¦è¸éµå¾ªï¼š
===================
1. **è³‡æ–™è™•ç†**ï¼šä½¿ç”¨ pm.MutableData åŒ…è£è¼¸å…¥è³‡æ–™ï¼Œä¾¿æ–¼é æ¸¬å’Œæ›´æ–°
2. **åº§æ¨™ç³»çµ±**ï¼šå®šç¾©æ˜ç¢ºçš„ç¶­åº¦åº§æ¨™ï¼Œæé«˜æ¨¡å‹å¯è®€æ€§
3. **æ•¸å€¼ç©©å®šæ€§**ï¼šä½¿ç”¨ pm.math.clip é˜²æ­¢æ•¸å€¼æº¢å‡ºï¼Œæ·»åŠ  epsilon è™•ç†é‚Šç•Œæƒ…æ³
4. **å…ˆé©—è¨­å®š**ï¼šä½¿ç”¨é©åº¦è³‡è¨Šæ€§å…ˆé©—ï¼Œæ·»åŠ  initval æé«˜æ”¶æ–‚æ€§
5. **æ¡æ¨£è¨­å®š**ï¼šä½¿ç”¨å¤šéˆå¹³è¡Œæ¡æ¨£ï¼Œé©ç•¶çš„ target_accept å’Œ max_treedepth
6. **æ¨¡å‹è¨ºæ–·**ï¼šå…¨é¢çš„æ”¶æ–‚æ€§æª¢æŸ¥ï¼ŒåŒ…æ‹¬ R-hatã€ESSã€ç™¼æ•£è½‰æ›
7. **æ¨è«–æ–¹æ³•**ï¼šMCMC å’Œ ADVI çš„æ­£ç¢ºè¨­å®šå’Œä½¿ç”¨
8. **è¦–è¦ºåŒ–**ï¼šä½¿ç”¨ ArviZ é€²è¡Œæ¨™æº–åŒ–çš„è²æ°åˆ†æè¦–è¦ºåŒ–

åŸ·è¡Œæ–¹æ³•:
$env:PYTHONIOENCODING='utf-8'; $env:PYTHONUTF8='1'; python PyMC_BuyerSeller_ClogLog_250527.py
"""

import multiprocessing
import numpy as np
import pymc as pm
import pandas as pd
import warnings
import arviz as az
import pytensor.tensor as pt

# è¦–è¦ºåŒ–ç›¸é—œ
try:
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')  # ä½¿ç”¨éäº’å‹•å¼å¾Œç«¯ï¼Œé©åˆä¼ºæœå™¨ç’°å¢ƒ
    

    # å‹•æ…‹æª¢æŸ¥å’Œè¨­å®šä¸­æ–‡å­—é«”
    def setup_chinese_font():
        """è¨­å®šä¸­æ–‡å­—é«”æ”¯æ´"""
        from matplotlib.font_manager import FontManager
        
        # æª¢æŸ¥å¯ç”¨çš„ä¸­æ–‡å­—é«”
        fm = FontManager()
        available_fonts = [f.name for f in fm.ttflist]
        
        # å„ªå…ˆé †åºçš„ä¸­æ–‡å­—é«”åˆ—è¡¨
        preferred_fonts = [
            'Microsoft YaHei',  # Windows å¾®è»Ÿé›…é»‘
            'SimHei',          # Windows é»‘é«”
            'SimSun',          # Windows å®‹é«”
            'WenQuanYi Micro Hei',  # Linux æ–‡æ³‰é©›å¾®ç±³é»‘
            'Noto Sans CJK SC',     # Linux Noto Sans
            'PingFang SC',          # macOS è˜‹æ–¹
            'Heiti SC',            # macOS é»‘é«”
            'Arial Unicode MS'      # é€šç”¨ Unicode å­—é«”
        ]
        
        # æ‰¾åˆ°ç¬¬ä¸€å€‹å¯ç”¨çš„ä¸­æ–‡å­—é«”
        selected_font = None
        for font in preferred_fonts:
            if font in available_fonts:
                selected_font = font
                break
        
        if selected_font:
            plt.rcParams['font.sans-serif'] = [selected_font, 'DejaVu Sans', 'sans-serif']
            print(f"âœ“ ä½¿ç”¨ä¸­æ–‡å­—é«”: {selected_font}")
        else:
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'sans-serif']
            print("âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œä½¿ç”¨é è¨­å­—é«”")
        
        plt.rcParams['axes.unicode_minus'] = False  # è§£æ±ºè² è™Ÿé¡¯ç¤ºå•é¡Œ
        plt.rcParams['font.size'] = 10  # è¨­å®šåŸºæœ¬å­—é«”å¤§å°
        
        return selected_font is not None
    
    # è¨­å®šä¸­æ–‡å­—é«”
    chinese_font_available = setup_chinese_font()
    
    # æ¸¬è©¦ä¸­æ–‡å­—é«”æ˜¯å¦å¯ç”¨
    try:
        fig, ax = plt.subplots(figsize=(1, 1))
        ax.text(0.5, 0.5, 'æ¸¬è©¦ä¸­æ–‡', ha='center', va='center')
        plt.close(fig)
        if chinese_font_available:
            print("âœ“ Matplotlib å¯ç”¨ï¼Œä¸­æ–‡å­—é«”æ”¯æ´æ­£å¸¸")
        else:
            print("âš ï¸ Matplotlib å¯ç”¨ï¼Œä½†ä¸­æ–‡å­—é«”æ”¯æ´æœ‰é™")
    except Exception as e:
        print(f"âš ï¸ ä¸­æ–‡å­—é«”æ¸¬è©¦å¤±æ•—: {e}")
        chinese_font_available = False
    
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    print("âš ï¸ Matplotlib ä¸å¯ç”¨ï¼Œå°‡è·³éå¾Œé©—åˆ†ä½ˆè¦–è¦ºåŒ–")

# å¿½ç•¥æ•¸å€¼è­¦å‘Š
warnings.filterwarnings('ignore')

# GraphViz è¦–è¦ºåŒ–ç›¸é—œ
try:
    import graphviz
    GRAPHVIZ_AVAILABLE = True
    print("âœ“ GraphViz å¯ç”¨ï¼Œå°‡ç”Ÿæˆæ¨¡å‹çµæ§‹åœ–")
except ImportError:
    GRAPHVIZ_AVAILABLE = False
    print("âš ï¸ GraphViz ä¸å¯ç”¨ï¼Œå°‡è·³éæ¨¡å‹çµæ§‹è¦–è¦ºåŒ–")
    print("  å®‰è£æ–¹æ³•: pip install graphviz")

def visualize_model_structure(model, model_name, save_file=True):
    """
    è¦–è¦ºåŒ– PyMC æ¨¡å‹çµæ§‹
    
    åƒæ•¸ï¼š
    - model: PyMC æ¨¡å‹å°è±¡
    - model_name: æ¨¡å‹åç¨±ï¼Œç”¨æ–¼æª”æ¡ˆå‘½å
    - save_file: æ˜¯å¦ä¿å­˜åœ–ç‰‡æª”æ¡ˆ
    """
    if not GRAPHVIZ_AVAILABLE:
        print(f"âš ï¸ è·³é {model_name} æ¨¡å‹çµæ§‹è¦–è¦ºåŒ–ï¼ˆGraphViz Python å¥—ä»¶ä¸å¯ç”¨ï¼‰")
        print("  å®‰è£æ–¹æ³•: pip install graphviz")
        return None
    
    try:
        print(f"\n ç”Ÿæˆ {model_name} æ¨¡å‹çµæ§‹åœ–...")
        
        # ç”Ÿæˆæ¨¡å‹çµæ§‹åœ–
        graph = pm.model_to_graphviz(model)
        
        if graph is not None:
            # è¨­å®šåœ–ç‰‡å±¬æ€§
            graph.attr(rankdir='TB')  # å¾ä¸Šåˆ°ä¸‹çš„å¸ƒå±€
            graph.attr('node', shape='ellipse', style='filled', fillcolor='lightblue')
            graph.attr('graph', bgcolor='white', dpi='300')
            
            if save_file:
                # ä¿å­˜ç‚º PNG æ ¼å¼
                filename = f"model_structure_{model_name.replace(' ', '_')}"
                try:
                    graph.render(filename, format='png', cleanup=True)
                    print(f"âœ“ {model_name} æ¨¡å‹çµæ§‹åœ–å·²ä¿å­˜ç‚º: {filename}.png")
                except Exception as e:
                    error_msg = str(e)
                    if "failed to execute" in error_msg and "dot" in error_msg:
                        print(f"âš ï¸ GraphViz ç³»çµ±åŸ·è¡Œæª”æœªå®‰è£æˆ–ä¸åœ¨ PATH ä¸­")
                        print("  Windows å®‰è£æ–¹æ³•:")
                        print("    1. ä¸‹è¼‰ GraphViz: https://graphviz.org/download/")
                        print("    2. å®‰è£å¾Œå°‡ bin ç›®éŒ„æ·»åŠ åˆ°ç³»çµ± PATH")
                        print("    3. æˆ–ä½¿ç”¨ conda: conda install graphviz")
                        print("  è·³éæ¨¡å‹çµæ§‹åœ–ç”Ÿæˆ...")
                    else:
                        print(f"âš ï¸ ä¿å­˜åœ–ç‰‡å¤±æ•—: {e}")
            
            print(f"âœ“ {model_name} æ¨¡å‹çµæ§‹åœ–ç”ŸæˆæˆåŠŸï¼ˆä½†å¯èƒ½æœªä¿å­˜ï¼‰")
            return graph
        else:
            print(f"âš ï¸ {model_name} æ¨¡å‹çµæ§‹åœ–ç”Ÿæˆå¤±æ•—")
            return None
            
    except Exception as e:
        print(f"âŒ {model_name} æ¨¡å‹çµæ§‹è¦–è¦ºåŒ–å¤±æ•—: {e}")
        if "graphviz" in str(e).lower():
            print("  å»ºè­°: å®‰è£å®Œæ•´çš„ GraphViz ç³»çµ±å¥—ä»¶")
        return None


def analyze_model_structure(model, model_name):
    """
    åˆ†ææ¨¡å‹çµæ§‹ä¸¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
    
    åƒæ•¸ï¼š
    - model: PyMC æ¨¡å‹å°è±¡  
    - model_name: æ¨¡å‹åç¨±
    """
    print(f"\n{model_name} æ¨¡å‹çµæ§‹åˆ†æ:")
    print("-" * 50)
    
    try:
        # ç²å–æ¨¡å‹ä¸­çš„æ‰€æœ‰è®Šæ•¸
        free_vars = model.free_RVs
        observed_vars = model.observed_RVs
        deterministic_vars = model.deterministics
        
        print(f"è‡ªç”±éš¨æ©Ÿè®Šæ•¸ ({len(free_vars)}å€‹):")
        for var in free_vars:
            print(f"  â€¢ {var.name}: {var.type}")
            
        print(f"\nè§€æ¸¬è®Šæ•¸ ({len(observed_vars)}å€‹):")
        for var in observed_vars:
            print(f"  â€¢ {var.name}: {var.type}")
            
        print(f"\nç¢ºå®šæ€§è®Šæ•¸ ({len(deterministic_vars)}å€‹):")
        for var in deterministic_vars:
            print(f"  â€¢ {var.name}: è¨ˆç®—å¾—å‡ºçš„ä¸­é–“è®Šæ•¸")
            
        # è¨ˆç®—ç¸½åƒæ•¸æ•¸é‡
        total_params = sum(var.size.eval() for var in free_vars)
        print(f"\n æ¨¡å‹ç¸½è¦½:")
        print(f"  â€¢ ç¸½åƒæ•¸æ•¸é‡: {total_params}")
        print(f"  â€¢ æ¨¡å‹è¤‡é›œåº¦: {'é«˜' if total_params > 5 else 'ä¸­' if total_params > 2 else 'ä½'}")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹çµæ§‹åˆ†æå¤±æ•—: {e}")


def sample_and_visualize_prior_posterior(model, model_name, observed_data, save_plots=True):
    """
    é€²è¡Œå…ˆé©—å’Œå¾Œé©—æ¡æ¨£ï¼Œä¸¦è¦–è¦ºåŒ–åˆ†ä½ˆ
    
    åƒæ•¸ï¼š
    - model: PyMC æ¨¡å‹å°è±¡
    - model_name: æ¨¡å‹åç¨±
    - observed_data: è§€æ¸¬è³‡æ–™ (æ¥å—è¡Œç‚º a_ij)
    - save_plots: æ˜¯å¦ä¿å­˜åœ–ç‰‡
    """
    if not MATPLOTLIB_AVAILABLE:
        print(f"âš ï¸ è·³é {model_name} å¾Œé©—åˆ†ä½ˆè¦–è¦ºåŒ–ï¼ˆMatplotlib ä¸å¯ç”¨ï¼‰")
        return None, None
    
    print(f"\n {model_name} å…ˆé©—å’Œå¾Œé©—åˆ†ä½ˆåˆ†æ...")
    
    try:
        with model:
            try:
                # 1. å…ˆé©—é æ¸¬æ¡æ¨£ - ä½¿ç”¨ç¾ä»£API
                print("   é€²è¡Œå…ˆé©—é æ¸¬æ¡æ¨£...")
                prior_samples = pm.sample_prior_predictive(
                    samples=500, 
                    random_seed=123,
                    return_inferencedata=True
                )
                print("  âœ“ å…ˆé©—é æ¸¬æ¡æ¨£æˆåŠŸ")
                
                # 2. å¾Œé©—é æ¸¬æ¡æ¨£ï¼ˆéœ€è¦å…ˆæœ‰ MCMC traceï¼‰
                print("  æ³¨æ„ï¼šå¾Œé©—é æ¸¬æ¡æ¨£å°‡åœ¨ MCMC å®Œæˆå¾Œé€²è¡Œ")
                
            except Exception as e:
                print(f"  âŒ å…ˆé©—é æ¸¬æ¡æ¨£å¤±æ•—: {e}")
                prior_samples = None
            
        return prior_samples, None
        
    except Exception as e:
        print(f"âŒ {model_name} å…ˆé©—æ¡æ¨£å¤±æ•—: {e}")
        return None, None


def visualize_posterior_distributions(trace, model_name, observed_data, prior_samples=None, save_plots=True):
    """
    è¦–è¦ºåŒ–å¾Œé©—åˆ†ä½ˆ
    
    åƒæ•¸ï¼š
    - trace: MCMC æ¡æ¨£çµæœ
    - model_name: æ¨¡å‹åç¨±
    - observed_data: è§€æ¸¬è³‡æ–™
    - prior_samples: å…ˆé©—æ¨£æœ¬ï¼ˆå¯é¸ï¼‰
    - save_plots: æ˜¯å¦ä¿å­˜åœ–ç‰‡
    """
    if not MATPLOTLIB_AVAILABLE:
        print(f"âš ï¸ è·³é {model_name} å¾Œé©—åˆ†ä½ˆè¦–è¦ºåŒ–ï¼ˆMatplotlib ä¸å¯ç”¨ï¼‰")
        return
    
    print(f"\n{model_name} å¾Œé©—åˆ†ä½ˆè¦–è¦ºåŒ–...")
    
    try:
        # 1. åƒæ•¸å¾Œé©—åˆ†ä½ˆåœ–
        print("  ç”Ÿæˆåƒæ•¸å¾Œé©—åˆ†ä½ˆåœ–...")
        
        # ç²å–å¯è¦–è¦ºåŒ–çš„åƒæ•¸ï¼ˆæ’é™¤é«˜ç¶­åº¦åƒæ•¸ï¼‰
        scalar_params = []
        for var_name in trace.posterior.data_vars:
            var_shape = trace.posterior[var_name].shape
            if len(var_shape) <= 3 and np.prod(var_shape[2:]) <= 10:  # æœ€å¤š10å€‹å…ƒç´ 
                scalar_params.append(var_name)
        
        if scalar_params:
            fig = az.plot_posterior(trace, var_names=scalar_params, 
                                  figsize=(12, 8), round_to=3)
            if save_plots:
                filename = f"posterior_distributions_{model_name.replace(' ', '_')}.png"
                plt.savefig(filename, dpi=300, bbox_inches='tight')
                print(f"  âœ“ åƒæ•¸å¾Œé©—åˆ†ä½ˆåœ–å·²ä¿å­˜: {filename}")
            plt.close()
        
        # 2. è»Œè·¡åœ–ï¼ˆTrace plotsï¼‰
        print("  ç”Ÿæˆ MCMC è»Œè·¡åœ–...")
        if scalar_params:
            fig = az.plot_trace(trace, var_names=scalar_params, 
                               figsize=(12, len(scalar_params)*2))
            if save_plots:
                filename = f"mcmc_traces_{model_name.replace(' ', '_')}.png"
                plt.savefig(filename, dpi=300, bbox_inches='tight')
                print(f"  âœ“ MCMC è»Œè·¡åœ–å·²ä¿å­˜: {filename}")
            plt.close()
        
        # 3. è§€æ¸¬å€¼ vs é æ¸¬å€¼æ¯”è¼ƒ
        print("  ç”Ÿæˆè§€æ¸¬å€¼èˆ‡é æ¸¬å€¼æ¯”è¼ƒåœ–...")
        
        # ç²å–å¾Œé©—é æ¸¬æ©Ÿç‡
        if "p_acceptance" in trace.posterior:
            p_pred = trace.posterior["p_acceptance"].mean(dim=["chain", "draw"]).values
            
            # å‰µå»ºæ¯”è¼ƒåœ–
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            
            # æ¥å—ç‡æ¯”è¼ƒ
            obs_accept_rate = np.mean(observed_data)
            pred_accept_rate = np.mean(p_pred)
            
            axes[0, 0].bar(['è§€æ¸¬å€¼', 'é æ¸¬å€¼'], [obs_accept_rate, pred_accept_rate], 
                          color=['skyblue', 'lightcoral'], alpha=0.7)
            axes[0, 0].set_title('æ¥å—ç‡æ¯”è¼ƒ', fontsize=12, fontweight='bold')
            axes[0, 0].set_ylabel('æ¥å—ç‡', fontsize=10)
            axes[0, 0].set_ylim(0, 1)
            
            # é æ¸¬æ©Ÿç‡åˆ†ä½ˆ
            axes[0, 1].hist(p_pred, bins=30, alpha=0.7, color='lightgreen', 
                           label=f'é æ¸¬æ©Ÿç‡ (å¹³å‡={pred_accept_rate:.3f})')
            axes[0, 1].axvline(obs_accept_rate, color='red', linestyle='--', 
                              label=f'è§€æ¸¬æ¥å—ç‡={obs_accept_rate:.3f}')
            axes[0, 1].set_title('é æ¸¬æ©Ÿç‡åˆ†ä½ˆ', fontsize=12, fontweight='bold')
            axes[0, 1].set_xlabel('æ¥å—æ©Ÿç‡', fontsize=10)
            axes[0, 1].set_ylabel('é »ç‡', fontsize=10)
            axes[0, 1].legend(prop={'size': 9})
            
            # é æ¸¬ vs è§€æ¸¬æ•£é»åœ–
            pred_binary = (p_pred > 0.5).astype(int)
            correct_predictions = (pred_binary == observed_data)
            
            axes[1, 0].scatter(p_pred[correct_predictions], observed_data[correct_predictions], 
                              alpha=0.6, color='green', label='æ­£ç¢ºé æ¸¬', s=20)
            axes[1, 0].scatter(p_pred[~correct_predictions], observed_data[~correct_predictions], 
                              alpha=0.6, color='red', label='éŒ¯èª¤é æ¸¬', s=20)
            axes[1, 0].plot([0, 1], [0, 1], 'k--', alpha=0.5)
            axes[1, 0].set_xlabel('é æ¸¬æ©Ÿç‡', fontsize=10)
            axes[1, 0].set_ylabel('è§€æ¸¬å€¼', fontsize=10)
            axes[1, 0].set_title('é æ¸¬ vs è§€æ¸¬', fontsize=12, fontweight='bold')
            axes[1, 0].legend(prop={'size': 9})
            
            # æ··æ·†çŸ©é™£
            tp = np.sum((pred_binary == 1) & (observed_data == 1))
            tn = np.sum((pred_binary == 0) & (observed_data == 0))
            fp = np.sum((pred_binary == 1) & (observed_data == 0))
            fn = np.sum((pred_binary == 0) & (observed_data == 1))
            
            confusion_matrix = np.array([[tn, fp], [fn, tp]])
            im = axes[1, 1].imshow(confusion_matrix, cmap='Blues', alpha=0.7)
            
            # æ·»åŠ æ•¸å­—æ¨™ç±¤
            for i in range(2):
                for j in range(2):
                    axes[1, 1].text(j, i, f'{confusion_matrix[i, j]}',
                                   ha="center", va="center", fontsize=14, fontweight='bold')
            
            axes[1, 1].set_xticks([0, 1])
            axes[1, 1].set_yticks([0, 1])
            axes[1, 1].set_xticklabels(['é æ¸¬æ‹’çµ•', 'é æ¸¬æ¥å—'], fontsize=9)
            axes[1, 1].set_yticklabels(['å¯¦éš›æ‹’çµ•', 'å¯¦éš›æ¥å—'], fontsize=9)
            axes[1, 1].set_title('æ··æ·†çŸ©é™£', fontsize=12, fontweight='bold')
            
            plt.tight_layout()
            
            if save_plots:
                filename = f"prediction_comparison_{model_name.replace(' ', '_')}.png"
                plt.savefig(filename, dpi=300, bbox_inches='tight')
                print(f"  âœ“ é æ¸¬æ¯”è¼ƒåœ–å·²ä¿å­˜: {filename}")
            plt.close()
        
        # 4. å…ˆé©— vs å¾Œé©—æ¯”è¼ƒï¼ˆå¦‚æœæœ‰å…ˆé©—æ¨£æœ¬ï¼‰
        if prior_samples is not None and "acceptance_likelihood" in prior_samples.prior_predictive:
            print("   ç”Ÿæˆå…ˆé©— vs å¾Œé©—æ¯”è¼ƒåœ–...")
            
            # å¾Œé©—é æ¸¬æ¡æ¨£ - ä½¿ç”¨æ­£ç¢ºçš„æ–¹æ³•
            try:
                # ç²å–æ¨¡å‹å¯¦ä¾‹
                model_instance = trace.posterior.attrs.get("model", None)
                
                if model_instance is not None:
                    with model_instance:
                        posterior_pred = pm.sample_posterior_predictive(
                            trace, 
                            samples=500, 
                            random_seed=123,
                            return_inferencedata=True,
                            progressbar=False
                        )
                else:
                    print("    âš ï¸ ç„¡æ³•ç²å–æ¨¡å‹å¯¦ä¾‹ï¼Œè·³éå¾Œé©—é æ¸¬")
                    posterior_pred = None
                    
            except Exception as e:
                print(f"    âŒ å¾Œé©—é æ¸¬æ¡æ¨£å¤±æ•—: {e}")
                posterior_pred = None
            
            fig, ax = plt.subplots(1, 1, figsize=(10, 6))
            
            # æª¢æŸ¥å¾Œé©—é æ¸¬æ˜¯å¦å¯ç”¨
            if posterior_pred is not None:
                # è§€æ¸¬å€¼åˆ†ä½ˆ
                ax.hist(observed_data, bins=3, alpha=0.6, color="blue", 
                       label="è§€æ¸¬å€¼", density=True)
                
                # å…ˆé©—é æ¸¬åˆ†ä½ˆ
                if hasattr(prior_samples, 'prior_predictive') and "acceptance_likelihood" in prior_samples.prior_predictive:
                    prior_pred = prior_samples.prior_predictive["acceptance_likelihood"].values.flatten()
                    ax.hist(prior_pred, bins=3, alpha=0.6, color="red", 
                           label="å…ˆé©—é æ¸¬", density=True)
                
                # å¾Œé©—é æ¸¬åˆ†ä½ˆ
                if hasattr(posterior_pred, 'posterior_predictive') and "acceptance_likelihood" in posterior_pred.posterior_predictive:
                    posterior_pred_vals = posterior_pred.posterior_predictive["acceptance_likelihood"].values.flatten()
                    ax.hist(posterior_pred_vals, bins=3, alpha=0.6, color="green", 
                           label="å¾Œé©—é æ¸¬", density=True)
            else:
                # åªé¡¯ç¤ºè§€æ¸¬å€¼å’Œå…ˆé©—é æ¸¬
                ax.hist(observed_data, bins=3, alpha=0.6, color="blue", 
                       label="è§€æ¸¬å€¼", density=True)
                
                if hasattr(prior_samples, 'prior_predictive') and "acceptance_likelihood" in prior_samples.prior_predictive:
                    prior_pred = prior_samples.prior_predictive["acceptance_likelihood"].values.flatten()
                    ax.hist(prior_pred, bins=3, alpha=0.6, color="red", 
                           label="å…ˆé©—é æ¸¬", density=True)
                
                ax.text(0.5, 0.8, "å¾Œé©—é æ¸¬ä¸å¯ç”¨", transform=ax.transAxes, 
                       bbox=dict(boxstyle="round", facecolor='wheat', alpha=0.5))
            
            ax.set_xlabel('æ¥å—è¡Œç‚º (0=æ‹’çµ•, 1=æ¥å—)', fontsize=10)
            ax.set_ylabel('é »ç‡', fontsize=10)
            ax.set_title('è§€æ¸¬å€¼ vs å…ˆé©—é æ¸¬ vs å¾Œé©—é æ¸¬', fontsize=12, fontweight='bold')
            ax.legend(prop={'size': 9})
            
            if save_plots:
                filename = f"prior_posterior_comparison_{model_name.replace(' ', '_')}.png"
                plt.savefig(filename, dpi=300, bbox_inches='tight')
                print(f"  âœ“ å…ˆé©—å¾Œé©—æ¯”è¼ƒåœ–å·²ä¿å­˜: {filename}")
            plt.close()
        
        print(f"  âœ“ {model_name} å¾Œé©—åˆ†ä½ˆè¦–è¦ºåŒ–å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ {model_name} å¾Œé©—åˆ†ä½ˆè¦–è¦ºåŒ–å¤±æ•—: {e}")


def generate_model_diagnostics(trace, model_name, save_plots=True):
    """
    ç”Ÿæˆæ¨¡å‹è¨ºæ–·åœ–
    
    åƒæ•¸ï¼š
    - trace: MCMC æ¡æ¨£çµæœ
    - model_name: æ¨¡å‹åç¨±
    - save_plots: æ˜¯å¦ä¿å­˜åœ–ç‰‡
    """
    if not MATPLOTLIB_AVAILABLE:
        print(f"âš ï¸ è·³é {model_name} æ¨¡å‹è¨ºæ–·ï¼ˆMatplotlib ä¸å¯ç”¨ï¼‰")
        return
    
    print(f"\n{model_name} æ¨¡å‹è¨ºæ–·...")
    
    try:
        # 1. R-hat è¨ºæ–· - æª¢æŸ¥æ”¶æ–‚æ€§
        print(f"   R-hat è¨ºæ–·ï¼ˆæ‡‰æ¥è¿‘1.0ï¼‰:")
        rhat = az.rhat(trace)
        max_rhat = 0
        rhat_warnings = []
        
        for var_name in rhat.data_vars:
            rhat_val = rhat[var_name]
            if rhat_val.size == 1:
                val = float(rhat_val.values)
                print(f"    â€¢ {var_name}: {val:.4f}")
                if val > 1.01:
                    rhat_warnings.append(f"{var_name}: {val:.4f}")
                max_rhat = max(max_rhat, val)
            else:
                mean_val = float(np.mean(rhat_val.values))
                max_val = float(np.max(rhat_val.values))
                print(f"    â€¢ {var_name}: {mean_val:.4f} (å¹³å‡), {max_val:.4f} (æœ€å¤§)")
                if max_val > 1.01:
                    rhat_warnings.append(f"{var_name}: {max_val:.4f}")
                max_rhat = max(max_rhat, max_val)
        
        if rhat_warnings:
            print(f"    âš ï¸ R-hat è­¦å‘Š (>1.01): {', '.join(rhat_warnings)}")
        else:
            print(f"    âœ“ æ‰€æœ‰ R-hat å€¼éƒ½è‰¯å¥½ (<1.01)")
        
        # 2. æœ‰æ•ˆæ¨£æœ¬æ•¸ (ESS) è¨ºæ–·
        print(f"\n  æœ‰æ•ˆæ¨£æœ¬æ•¸è¨ºæ–·:")
        try:
            # å˜—è©¦æ–°ç‰ˆæœ¬ API
            ess_bulk = az.ess(trace, method="bulk")
            ess_tail = az.ess(trace, method="tail")
        except TypeError:
            try:
                # å˜—è©¦èˆŠç‰ˆæœ¬ API
                ess_bulk = az.ess(trace, kind="bulk")
                ess_tail = az.ess(trace, kind="tail")
            except TypeError:
                # ä½¿ç”¨æœ€åŸºæœ¬çš„ ESS è¨ˆç®—
                ess_bulk = az.ess(trace)
                ess_tail = az.ess(trace)
        
        min_ess_bulk = float('inf')
        min_ess_tail = float('inf')
        ess_warnings = []
        
        for var_name in ess_bulk.data_vars:
            if var_name in ess_tail.data_vars:
                bulk_val = ess_bulk[var_name]
                tail_val = ess_tail[var_name]
                
                if bulk_val.size == 1:
                    bulk = float(bulk_val.values)
                    tail = float(tail_val.values)
                    print(f"    â€¢ {var_name}: bulk={bulk:.0f}, tail={tail:.0f}")
                    if bulk < 400 or tail < 400:
                        ess_warnings.append(f"{var_name}")
                    min_ess_bulk = min(min_ess_bulk, bulk)
                    min_ess_tail = min(min_ess_tail, tail)
                else:
                    bulk_mean = float(np.mean(bulk_val.values))
                    tail_mean = float(np.mean(tail_val.values))
                    bulk_min = float(np.min(bulk_val.values))
                    tail_min = float(np.min(tail_val.values))
                    print(f"    â€¢ {var_name}: bulk={bulk_mean:.0f} (avg), tail={tail_mean:.0f} (avg)")
                    if bulk_min < 400 or tail_min < 400:
                        ess_warnings.append(f"{var_name}")
                    min_ess_bulk = min(min_ess_bulk, bulk_min)
                    min_ess_tail = min(min_ess_tail, tail_min)
        
        if ess_warnings:
            print(f"    âš ï¸ ESS è­¦å‘Š (<400): {', '.join(ess_warnings)}")
        else:
            print(f"    âœ“ æ‰€æœ‰ ESS å€¼éƒ½å……è¶³ (â‰¥400)")
        
        # 3. ç™¼æ•£è½‰æ›æª¢æŸ¥
        if hasattr(trace, 'sample_stats') and 'diverging' in trace.sample_stats:
            n_divergent = int(trace.sample_stats.diverging.sum())
            print(f"\n  ç™¼æ•£è½‰æ›: {n_divergent} å€‹")
            if n_divergent > 0:
                print(f"    âš ï¸ ç™¼ç¾ç™¼æ•£è½‰æ›ï¼Œå»ºè­°å¢åŠ  target_accept æˆ–æª¢æŸ¥æ¨¡å‹")
            else:
                print(f"    âœ“ ç„¡ç™¼æ•£è½‰æ›")
        
        # 4. èƒ½é‡åœ–è¨ºæ–·
        if MATPLOTLIB_AVAILABLE:
            print("  âš¡ ç”Ÿæˆèƒ½é‡è¨ºæ–·åœ–...")
            try:
                fig = az.plot_energy(trace, figsize=(10, 6))
                if save_plots:
                    filename = f"energy_diagnostic_{model_name.replace(' ', '_')}.png"
                    plt.savefig(filename, dpi=300, bbox_inches='tight')
                    print(f"    âœ“ èƒ½é‡è¨ºæ–·åœ–å·²ä¿å­˜: {filename}")
                plt.close()
            except Exception as e:
                print(f"    âš ï¸ èƒ½é‡åœ–ç”Ÿæˆå¤±æ•—: {e}")
        
        # 5. ç¶œåˆè¨ºæ–·çµæœ
        print(f"\n   è¨ºæ–·çµæœç¸½çµ:")
        print(f"    â€¢ æœ€å¤§ R-hat: {max_rhat:.4f}")
        print(f"    â€¢ æœ€å° ESS (bulk): {min_ess_bulk:.0f}")
        print(f"    â€¢ æœ€å° ESS (tail): {min_ess_tail:.0f}")
        
        overall_status = "è‰¯å¥½"
        if max_rhat > 1.01 or min_ess_bulk < 400 or min_ess_tail < 400:
            overall_status = "éœ€è¦é—œæ³¨"
        if max_rhat > 1.1 or min_ess_bulk < 100 or min_ess_tail < 100:
            overall_status = "æœ‰å•é¡Œ"
        
        print(f"    â€¢ æ•´é«”ç‹€æ…‹: {overall_status}")
        
        print(f"  âœ“ {model_name} æ¨¡å‹è¨ºæ–·å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ {model_name} æ¨¡å‹è¨ºæ–·å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


def check_data_validity(s_ij, a_ij, X_ij, x_ij):
    """æª¢æŸ¥è²·è³£é›™æ–¹äº’å‹•è³‡æ–™çš„æœ‰æ•ˆæ€§"""
    print("\næª¢æŸ¥è²·è³£é›™æ–¹äº’å‹•è³‡æ–™æœ‰æ•ˆæ€§...")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰ç„¡æ•ˆå€¼
    for name, data in [('s_ij', s_ij), ('a_ij', a_ij), ('X_ij', X_ij), ('x_ij', x_ij)]:
        if data.ndim == 1:
            n_nan = np.isnan(data).sum()
            n_inf = np.isinf(data).sum()
            print(f"{name}: NaN æ•¸é‡ = {n_nan}, Inf æ•¸é‡ = {n_inf}")
        else:
            n_nan = np.isnan(data).sum()
            n_inf = np.isinf(data).sum()
            print(f"{name}: NaN æ•¸é‡ = {n_nan}, Inf æ•¸é‡ = {n_inf}, å½¢ç‹€ = {data.shape}")
        
    # æª¢æŸ¥å€¼çš„ç¯„åœ
    print("\nè²·è³£é›™æ–¹äº’å‹•è³‡æ–™ç¯„åœ:")
    print(f"s_ij (è³£å®¶å›æ‡‰æ™‚é–“): æœ€å°å€¼ = {np.min(s_ij):.3f}, æœ€å¤§å€¼ = {np.max(s_ij):.3f}")
    print(f"a_ij (æ¥å—è¡Œç‚º): æœ€å°å€¼ = {np.min(a_ij):.3f}, æœ€å¤§å€¼ = {np.max(a_ij):.3f}")
    print(f"X_ij (c_ijå…±è®Šæ•¸): å½¢ç‹€ = {X_ij.shape}")
    print(f"x_ij (Ï„_ijå…±è®Šæ•¸): å½¢ç‹€ = {x_ij.shape}")


if __name__ == '__main__':
    multiprocessing.freeze_support()
    
    # ========================= 1. è²·è³£é›™æ–¹äº’å‹•è³‡æ–™æ¨¡æ“¬ =========================
    print("é–‹å§‹æ¨¡æ“¬è²·è³£é›™æ–¹äº’å‹•è³‡æ–™...")

    # è¨­å®šéš¨æ©Ÿæ•¸ç¨®å­ä»¥ç¢ºä¿çµæœå¯é‡ç¾
    RNG = np.random.default_rng(123)
    N = 5000  # æ¬¡æ•¸
    
    # å…±è®Šæ•¸ç¶­åº¦è¨­å®š
    num_covariates_X = 3  # å½±éŸ¿ c_ij çš„å…±è®Šæ•¸æ•¸é‡ (è²·å®¶ç‰¹å¾µã€å•†å“ç‰¹å¾µç­‰)
    num_covariates_x = 2  # å½±éŸ¿ Ï„_ij çš„å…±è®Šæ•¸æ•¸é‡ (è«‡åˆ¤ç‰¹å¾µç­‰)

    # ç”Ÿæˆå…±è®Šæ•¸
    # X_ij: å½±éŸ¿é€Ÿç‡åƒæ•¸ c_ij çš„é…å°å±¤ç´šå…±è®Šæ•¸
    X_ij = RNG.normal(size=(N, num_covariates_X))
    
    # x_ij: å½±éŸ¿æ™‚é–“ä¿‚æ•¸ Ï„_ij çš„ç‰¹å¾µå‘é‡  
    x_ij = RNG.normal(size=(N, num_covariates_x))

    # å®šç¾©çœŸå¯¦åƒæ•¸å€¼ - é‡å° Fraction link æ¨¡å‹å„ªåŒ–
    true_params = {
        "q": 2.5,           # Î»_ij çš„å½¢ç‹€åƒæ•¸ï¼ˆåƒ…ç”¨æ–¼ Clog-log æ¨¡å‹ï¼‰
        "gamma": 3.0,       # å¢åŠ åŸºç¤é€Ÿç‡åƒæ•¸ï¼Œç¢ºä¿ Î´_ij + Îº_ij è¶³å¤ å¤§
        "beta": np.array([0.2, -0.1, 0.3]),    # æ¸›å°ä¿‚æ•¸ï¼Œé¿å… Î´_ij éå°
        "theta": np.array([0.5, 0.3]),         # èª¿æ•´ç‚ºæ­£å€¼ï¼Œç¢ºä¿ Îº_ij è¶³å¤ å¤§
    }
    
    print("ğŸ”§ åƒæ•¸èª¿æ•´èªªæ˜:")
    print("  â€¢ gamma: 1.8 â†’ 3.0 (å¢åŠ åŸºç¤é€Ÿç‡)")
    print("  â€¢ beta: æ¸›å°ä¿‚æ•¸å¹…åº¦ï¼Œé¿å… exp(-X*Î²) éå¤§")
    print("  â€¢ theta: èª¿æ•´ç‚ºæ­£å€¼ï¼Œç¢ºä¿ Îº_ij = exp(x*Î¸) è¶³å¤ å¤§")
    print("  â€¢ ç›®æ¨™: ç¢ºä¿ Î´_ij + Îº_ij > max(s_ij) ä»¥é¿å…æ©Ÿç‡ > 1")

    # æ ¹æ“šçœŸå¯¦åƒæ•¸è¨ˆç®—æ½›åœ¨è®Šæ•¸
    print("è¨ˆç®—æ½›åœ¨è®Šæ•¸...")
    
    # c_ij: Î»_ij çš„é€Ÿç‡åƒæ•¸
    c_ij_true = true_params["gamma"] * np.exp(-X_ij @ true_params["beta"])
    
    # Ï„_ij: æ™‚é–“ä¿‚æ•¸
    tau_ij_true = np.exp(x_ij @ true_params["theta"])
    
    # ç”Ÿæˆè³£å®¶å›æ‡‰æ™‚é–“ s_ij - é‡å° Fraction link æ¨¡å‹èª¿æ•´
    # ä½¿ç”¨æ›´ä¿å®ˆçš„ç¯„åœï¼Œç¢ºä¿ä¸æœƒè¶…éåˆ†æ¯
    base_response_rate = 4.0  # å¢åŠ ç‡åƒæ•¸ï¼Œé™ä½å¹³å‡å›æ‡‰æ™‚é–“
    s_ij = RNG.exponential(scale=1/base_response_rate, size=N)
    # é™åˆ¶åœ¨æ›´å°çš„ç¯„åœå…§ï¼Œç¢ºä¿èˆ‡ Î´_ij + Îº_ij ç›¸å®¹
    s_ij = np.clip(s_ij, 0.05, 2.0)  # æ¸›å°ä¸Šé™ï¼š10.0 â†’ 2.0
    
    print(f"ğŸ“Š å›æ‡‰æ™‚é–“èª¿æ•´:")
    print(f"  â€¢ æœŸæœ›å€¼: {1/base_response_rate:.3f}")
    print(f"  â€¢ ç¯„åœ: [0.05, 2.0]")
    print(f"  â€¢ ç›®æ¨™: ç¢ºä¿ s_ij < Î´_ij + Îº_ij")

    # ç‚ºäº†æ¯”è¼ƒå…©ç¨®éˆæ¥å‡½æ•¸ï¼Œæˆ‘å€‘å°‡ç”ŸæˆåŒæ™‚é©ç”¨æ–¼å…©ç¨®æ¨¡å‹çš„è³‡æ–™
    # é¦–å…ˆä½¿ç”¨ Clog-log éˆæ¥å‡½æ•¸è¨ˆç®—æ¥å—æ©Ÿç‡
    print("è¨ˆç®— Clog-log æ¥å—æ©Ÿç‡...")
    p_acceptance_cloglog = 1 - (c_ij_true / (c_ij_true + tau_ij_true * s_ij))**true_params["q"]
    p_acceptance_cloglog = np.clip(p_acceptance_cloglog, 1e-6, 1-1e-6)
    
    # åŒæ™‚è¨ˆç®— Fraction link æ¥å—æ©Ÿç‡ (ç”¨æ–¼æ¯”è¼ƒ)
    print("è¨ˆç®— Fraction link æ¥å—æ©Ÿç‡...")
    # å°æ–¼ Fraction link: P(a=1|s,x) = s_ij / (Î´_ij + Îº_ij)
    # å…¶ä¸­ Î´_ij = c_ij_true, Îº_ij = tau_ij_true (é‡æ–°è§£é‡‹åƒæ•¸)
    delta_ij_true = c_ij_true
    kappa_ij_true = tau_ij_true
    
    # ç¢ºä¿åˆ†å­ä¸è¶…éåˆ†æ¯
    denominator_fraction = delta_ij_true + kappa_ij_true
    numerator_fraction = np.clip(s_ij, 1e-6, denominator_fraction - 1e-6)
    p_acceptance_fraction = numerator_fraction / denominator_fraction
    p_acceptance_fraction = np.clip(p_acceptance_fraction, 1e-6, 1-1e-6)
    
    # ğŸ” æª¢æŸ¥ Fraction link æ©Ÿç‡ç´„æŸ
    print(f"\nğŸ” Fraction Link æ©Ÿç‡ç´„æŸæª¢æŸ¥:")
    prob_violations = np.sum(p_acceptance_fraction >= 1.0)
    prob_over_09 = np.sum(p_acceptance_fraction > 0.9)
    
    print(f"  â€¢ æ©Ÿç‡ â‰¥ 1.0 çš„è§€æ¸¬æ•¸: {prob_violations} / {N} ({prob_violations/N*100:.1f}%)")
    print(f"  â€¢ æ©Ÿç‡ > 0.9 çš„è§€æ¸¬æ•¸: {prob_over_09} / {N} ({prob_over_09/N*100:.1f}%)")
    print(f"  â€¢ Î´_ij + Îº_ij å¹³å‡å€¼: {np.mean(denominator_fraction):.3f}")
    print(f"  â€¢ Î´_ij + Îº_ij æœ€å°å€¼: {np.min(denominator_fraction):.3f}")
    print(f"  â€¢ s_ij æœ€å¤§å€¼: {np.max(s_ij):.3f}")
    
    if prob_violations == 0:
        print(f"  âœ… æ‰€æœ‰æ©Ÿç‡éƒ½åœ¨ [0,1] ç¯„åœå…§")
    else:
        print(f"  âš ï¸ ä»æœ‰ {prob_violations} å€‹æ©Ÿç‡è¶…é 1.0")
    
    # é¸æ“‡åˆé©çš„è³‡æ–™ç”Ÿæˆéç¨‹
    print(f"\nğŸ“‹ é¸æ“‡è³‡æ–™ç”Ÿæˆæ–¹å¼:")
    print(f"  é¸é …1: ä½¿ç”¨ Clog-log éç¨‹ (åŸå§‹æ–¹æ³•)")
    print(f"  é¸é …2: ä½¿ç”¨ Fraction link éç¨‹ (é¿å…æ©Ÿç‡ç´„æŸå•é¡Œ)")
    
    # å¦‚æœ Fraction link æ²’æœ‰æ©Ÿç‡ç´„æŸå•é¡Œï¼Œä½¿ç”¨å®ƒä¾†ç”Ÿæˆè³‡æ–™
    if prob_violations == 0:
        print(f"  âœ… é¸æ“‡ Fraction link éç¨‹ç”Ÿæˆè³‡æ–™ (ç„¡ç´„æŸé•å)")
        p_acceptance_true = p_acceptance_fraction
    else:
        print(f"  âš ï¸ é¸æ“‡ Clog-log éç¨‹ç”Ÿæˆè³‡æ–™ (Fraction link æœ‰ç´„æŸé•å)")
        p_acceptance_true = p_acceptance_cloglog
    
    # ç”Ÿæˆæ¥å—è¡Œç‚º a_ij (äºŒå…ƒè®Šæ•¸)
    a_ij = RNG.binomial(1, p_acceptance_true)
    
    print(f"Clog-log å¹³å‡æ¥å—æ©Ÿç‡: {np.mean(p_acceptance_cloglog):.3f}")
    print(f"Fraction link å¹³å‡æ¥å—æ©Ÿç‡: {np.mean(p_acceptance_fraction):.3f}")
    print(f"å¯¦éš›è§€æ¸¬æ¥å—ç‡: {np.mean(a_ij):.3f}")

    # æª¢æŸ¥æ•¸æ“šæœ‰æ•ˆæ€§
    print("\n========== è²·è³£é›™æ–¹äº’å‹•æ•¸æ“šæª¢æŸ¥ ==========")
    print(f"è³£å®¶å›æ‡‰æ™‚é–“ (s_ij): å¹³å‡å€¼ = {np.mean(s_ij):.3f}, æ¨™æº–å·® = {np.std(s_ij):.3f}")
    print(f"æ¥å—è¡Œç‚º (a_ij): æ¥å—ç‡ = {np.mean(a_ij):.3f}")
    print(f"é€Ÿç‡åƒæ•¸ (c_ij): å¹³å‡å€¼ = {np.mean(c_ij_true):.3f}")
    print(f"æ™‚é–“ä¿‚æ•¸ (Ï„_ij): å¹³å‡å€¼ = {np.mean(tau_ij_true):.3f}")
    print("========================================\n")

    # å®šç¾©åº§æ¨™ç³»çµ±
    coords = {
        "obs": np.arange(N),
        "cov_X": np.arange(num_covariates_X), 
        "cov_x": np.arange(num_covariates_x)
    }

    # ========================= 2. æ¨¡å‹å»ºæ§‹å‡½æ•¸ =========================

    def build_cloglog_full_model(s_ij, a_ij, X_ij, x_ij, coords):
        """
        å»ºæ§‹å®Œæ•´çš„ Clog-log éˆæ¥æ¨¡å‹
        
        åŸºæ–¼ä»¥ä¸‹ç†è«–æ¡†æ¶ï¼š
        1. Latent-factor prior: Î»_ij ~ Î“(q, c_ij), c_ij = Î³*exp(-X_ij^T*Î²)
        2. SA equation: Ï„_ij = exp(x_ij^T*Î¸) 
        3. é‚Šéš›åŒ–å¾Œçš„æ¥å—æ©Ÿç‡: P(a=1|s,x) = 1 - (c_ij/(c_ij + Ï„_ij*s_ij))^q
        
        åƒæ•¸èªªæ˜ï¼š
        - q: å½¢ç‹€åƒæ•¸ï¼Œæ§åˆ¶æ¥å—æ©Ÿç‡èˆ‡å›æ‡‰æ™‚é–“çš„éç·šæ€§é—œä¿‚
        - Î³ (gamma): åŸºç¤é€Ÿç‡åƒæ•¸
        - Î² (beta): å½±éŸ¿ c_ij çš„å…±è®Šæ•¸ä¿‚æ•¸
        - Î¸ (theta): å½±éŸ¿ Ï„_ij çš„å…±è®Šæ•¸ä¿‚æ•¸
        """
        with pm.Model(coords=coords) as m:
            # ä½¿ç”¨ MutableData åŒ…è£è¼¸å…¥è³‡æ–™ (PyMC æœ€ä½³å¯¦è¸)
            s_data = pm.MutableData("s_data", s_ij, dims="obs")
            X_data = pm.MutableData("X_data", X_ij, dims=("obs", "cov_X"))
            x_data = pm.MutableData("x_data", x_ij, dims=("obs", "cov_x"))
            
            # å…ˆé©—åˆ†ä½ˆå®šç¾© - ä½¿ç”¨æ›´ä¿å®ˆçš„å…ˆé©—
            q = pm.HalfNormal("q", sigma=2, initval=1.5)
            gamma = pm.HalfNormal("gamma", sigma=2, initval=1.0)
            beta = pm.Normal("beta", mu=0, sigma=1, dims="cov_X", initval=np.zeros(X_ij.shape[1]))
            theta = pm.Normal("theta", mu=0, sigma=1, dims="cov_x", initval=np.zeros(x_ij.shape[1]))

            # ç¢ºå®šæ€§è®Šæ•¸è¨ˆç®— - æ·»åŠ æ•¸å€¼ç©©å®šæ€§
            linear_pred_c = pt.dot(X_data, beta)
            c_ij = pm.Deterministic("c_ij", gamma * pt.exp(-pm.math.clip(linear_pred_c, -10, 10)), dims="obs")
            
            linear_pred_tau = pt.dot(x_data, theta)
            tau_ij = pm.Deterministic("tau_ij", pt.exp(pm.math.clip(linear_pred_tau, -10, 10)), dims="obs")
            
            # æ¥å—æ©Ÿç‡ - æ”¹å–„æ•¸å€¼ç©©å®šæ€§
            eps = 1e-8
            denominator = c_ij + tau_ij * s_data + eps
            ratio = pm.math.clip(c_ij / denominator, eps, 1-eps)
            p_acceptance = pm.Deterministic("p_acceptance", 1 - pt.power(ratio, q), dims="obs")

            # ä¼¼ç„¶å‡½æ•¸
            acceptance_likelihood = pm.Bernoulli("acceptance_likelihood", p=p_acceptance, observed=a_ij, dims="obs")
            
        return m

    def build_fraction_link_model(s_ij, a_ij, X_ij, x_ij, coords):
        """
        å»ºæ§‹ Fraction link æ¨¡å‹ - å„ªåŒ–ç‰ˆæœ¬
        
        Fraction link æ¨¡å‹ï¼š
        Îº_ij = exp(x_ij^T * Î¸)
        Î´_ij = Î³ * exp(-X_ij^T * Î²) 
        æ¥å—æ©Ÿç‡: P(a=1|s,x) = s_ij / (Î´_ij + Îº_ij)
        
        å„ªåŒ–ç­–ç•¥ï¼š
        1. ä½¿ç”¨æ›´ä¿å®ˆçš„å…ˆé©—ï¼Œç¢ºä¿åˆ†æ¯è¶³å¤ å¤§
        2. æ·»åŠ é¡å¤–çš„æ•¸å€¼ç©©å®šæ€§ç´„æŸ
        3. ç¢ºä¿æ©Ÿç‡åš´æ ¼åœ¨ [0,1] ç¯„åœå…§
        """
        with pm.Model(coords=coords) as m:
            # ä½¿ç”¨ MutableData åŒ…è£è¼¸å…¥è³‡æ–™
            s_data = pm.MutableData("s_data", s_ij, dims="obs")
            X_data = pm.MutableData("X_data", X_ij, dims=("obs", "cov_X"))
            x_data = pm.MutableData("x_data", x_ij, dims=("obs", "cov_x"))
            
            # å„ªåŒ–çš„å…ˆé©—åˆ†ä½ˆ - ç¢ºä¿åˆ†æ¯è¶³å¤ å¤§
            gamma = pm.HalfNormal("gamma", sigma=1.5, initval=2.0)  # èª¿æ•´å…ˆé©—æœŸæœ›æ›´é«˜
            beta = pm.Normal("beta", mu=0, sigma=0.3, dims="cov_X", initval=np.zeros(X_ij.shape[1]))  # æ›´ä¿å®ˆ
            theta = pm.Normal("theta", mu=0.2, sigma=0.3, dims="cov_x", initval=np.zeros(x_ij.shape[1]))  # æ­£åç§»

            # ç¢ºå®šæ€§è®Šæ•¸è¨ˆç®— - æ›´å¼·çš„æ•¸å€¼ç©©å®šæ€§
            # Î´_ij: åŸºæº–åƒæ•¸ï¼Œç¢ºä¿ä¸æœƒå¤ªå°
            linear_pred_delta = pt.dot(X_data, beta)
            delta_ij = pm.Deterministic("delta_ij", 
                                       gamma * pt.exp(-pm.math.clip(linear_pred_delta, -3, 3)), 
                                       dims="obs")
            
            # Îº_ij: ç”±å”è®Šé‡æ±ºå®šçš„åƒæ•¸ï¼Œç¢ºä¿è¶³å¤ å¤§
            linear_pred_kappa = pt.dot(x_data, theta)
            kappa_ij = pm.Deterministic("kappa_ij", 
                                       pt.exp(pm.math.clip(linear_pred_kappa, -3, 5)),  # å…è¨±æ›´å¤§çš„ä¸Šé™
                                       dims="obs")
            
            # æ”¹é€²çš„ Fraction link æ¥å—æ©Ÿç‡
            eps = 1e-6
            denominator = delta_ij + kappa_ij + eps
            
            # æ–¹æ³•1: ç›´æ¥ç´„æŸåˆ†å­
            # numerator = pm.math.clip(s_data, eps, denominator - eps)
            # p_acceptance = pm.Deterministic("p_acceptance", numerator / denominator, dims="obs")
            
            # æ–¹æ³•2: ä½¿ç”¨ sigmoid ç¢ºä¿æ©Ÿç‡ç¯„åœ (æ›´ç©©å¥)
            raw_ratio = s_data / denominator
            p_acceptance = pm.Deterministic("p_acceptance", 
                                          pm.math.sigmoid(5 * (raw_ratio - 0.5)) * 0.98 + 0.01,  # æ˜ å°„åˆ° [0.01, 0.99]
                                          dims="obs")

            # ä¼¼ç„¶å‡½æ•¸
            acceptance_likelihood = pm.Bernoulli("acceptance_likelihood", p=p_acceptance, observed=a_ij, dims="obs")
            
        return m

    def build_fraction_link_model_improved(s_ij, a_ij, X_ij, x_ij, coords):
        """
        å»ºæ§‹æ”¹é€²çš„ Fraction link æ¨¡å‹ - æé«˜æ•¸å€¼ç©©å®šæ€§
        
        æ”¹é€²ç­–ç•¥ï¼š
        1. ä½¿ç”¨æ›´ç©©å®šçš„åƒæ•¸åŒ–
        2. æ·»åŠ æ•¸å€¼ç©©å®šæ€§ç´„æŸ
        3. ä½¿ç”¨æ›´ä¿å®ˆçš„å…ˆé©—åˆ†ä½ˆ
        4. é‡æ–°ç¸®æ”¾è¼¸å…¥è®Šæ•¸
        """
        with pm.Model(coords=coords) as m:
            # ä½¿ç”¨ MutableData åŒ…è£è¼¸å…¥è³‡æ–™
            s_data = pm.MutableData("s_data", s_ij, dims="obs")
            X_data = pm.MutableData("X_data", X_ij, dims=("obs", "cov_X"))
            x_data = pm.MutableData("x_data", x_ij, dims=("obs", "cov_x"))
            
            # æ”¹é€²çš„å…ˆé©—åˆ†ä½ˆ - æ›´ä¿å®ˆå’Œç©©å®š
            gamma = pm.HalfNormal("gamma", sigma=1.0, initval=0.5)  # æ›´å°çš„å…ˆé©—æ–¹å·®
            beta = pm.Normal("beta", mu=0, sigma=0.3, dims="cov_X", initval=np.zeros(X_ij.shape[1]))  # æ›´ä¿å®ˆ
            theta = pm.Normal("theta", mu=0, sigma=0.3, dims="cov_x", initval=np.zeros(x_ij.shape[1]))  # æ›´ä¿å®ˆ
            
            # ç©©å®šçš„ç·šæ€§é æ¸¬å™¨ - æ·»åŠ æ›´å¼·çš„ç´„æŸ
            linear_pred_delta = pt.dot(X_data, beta)
            linear_pred_kappa = pt.dot(x_data, theta)
            
            # æ”¹é€²çš„åƒæ•¸åŒ– - ç¢ºä¿æ•¸å€¼ç©©å®šæ€§
            delta_ij = pm.Deterministic("delta_ij", 
                                       gamma * pt.exp(-pm.math.clip(linear_pred_delta, -5, 5)), 
                                       dims="obs")
            
            kappa_ij = pm.Deterministic("kappa_ij", 
                                       pt.exp(pm.math.clip(linear_pred_kappa, -5, 5)), 
                                       dims="obs")
            
            # æ”¹é€²çš„ Fraction link å¯¦ç¾
            eps = 1e-6
            
            # ç¢ºä¿åˆ†æ¯ä¸æœƒå¤ªå°
            denominator = delta_ij + kappa_ij + eps
            
            # æ¨™æº–åŒ–åˆ†å­ï¼Œé¿å…æ©Ÿç‡è¶…é1
            # ä½¿ç”¨ sigmoid è®Šæ›ç¢ºä¿æ©Ÿç‡åœ¨åˆç†ç¯„åœå…§
            raw_ratio = s_data / denominator
            
            # ä½¿ç”¨ sigmoid å‡½æ•¸å°‡æ¯”ç‡æ˜ å°„åˆ° [0,1] å€é–“
            # é€™æ¨£å¯ä»¥é¿å…æ©Ÿç‡è¶…é1çš„å•é¡Œ
            p_acceptance = pm.Deterministic("p_acceptance", 
                                          pm.math.sigmoid(raw_ratio), 
                                          dims="obs")

            # ä¼¼ç„¶å‡½æ•¸
            acceptance_likelihood = pm.Bernoulli("acceptance_likelihood", 
                                                p=p_acceptance, 
                                                observed=a_ij, 
                                                dims="obs")
            
        return m

    # ========================= 3. æ¨¡å‹æ¨è«– =========================
    print("é–‹å§‹è²·è³£é›™æ–¹äº’å‹•æ¨¡å‹æ¨è«–...")
    
    # ========================= æ¨¡å‹çµæ§‹è¦–è¦ºåŒ– =========================
    print("\n" + "="*60)
    print("æ¨¡å‹çµæ§‹è¦–è¦ºåŒ–èˆ‡åˆ†æ")
    print("="*60)
    
    # å®Œæ•´ Clog-log æ¨¡å‹
    print("ä¼°è¨ˆå®Œæ•´ Clog-log æ¨¡å‹...")
    full_cloglog_model = build_cloglog_full_model(s_ij, a_ij, X_ij, x_ij, coords)
    
    # è¦–è¦ºåŒ–å®Œæ•´æ¨¡å‹çµæ§‹
    visualize_model_structure(full_cloglog_model, "å®Œæ•´_Clog-log_æ¨¡å‹")
    analyze_model_structure(full_cloglog_model, "å®Œæ•´ Clog-log æ¨¡å‹")
    
    # å…ˆé©—é æ¸¬æ¡æ¨£
    prior_samples_full, _ = sample_and_visualize_prior_posterior(
        full_cloglog_model, "å®Œæ•´ Clog-log æ¨¡å‹", a_ij)

    with full_cloglog_model:
        print("é€²è¡Œå®Œæ•´æ¨¡å‹ MAP ä¼°è¨ˆ...")
        try:
            map_estimate = pm.find_MAP()
            print("MAP ä¼°è¨ˆæˆåŠŸ")
        except Exception as e:
            print(f"MAP ä¼°è¨ˆå¤±æ•—: {e}")

        print("é–‹å§‹å®Œæ•´ Clog-log æ¨¡å‹ MCMC æ¡æ¨£...")
        # ä½¿ç”¨ PyMC æ¨è–¦çš„æ¡æ¨£åƒæ•¸
        trace_full_MCMC = pm.sample(
            draws=1000,
            tune=1000,
            chains=4,  # å¢åŠ éˆæ•¸ä»¥æé«˜æ”¶æ–‚æª¢æ¸¬
            cores=min(4, multiprocessing.cpu_count()),  # å¹³è¡Œè¨ˆç®—
            target_accept=0.95,  # æé«˜ç›®æ¨™æ¥å—ç‡
            max_treedepth=12,  # å¢åŠ æ¨¹æ·±åº¦ä»¥é¿å…divergence
            init="adapt_diag",  # ä½¿ç”¨å°è§’é©æ‡‰åˆå§‹åŒ–
            return_inferencedata=True,
            random_seed=123,
            progressbar=True  # é¡¯ç¤ºé€²åº¦æ¢
        )

    # é¡¯ç¤ºçµæœ
    print("\nå®Œæ•´ Clog-log æ¨¡å‹åƒæ•¸ä¼°è¨ˆçµæœ:")
    scalar_params = ["q", "gamma", "beta", "theta"]
    summary = az.summary(trace_full_MCMC, var_names=scalar_params)
    print(summary)

    # æ¯”è¼ƒçœŸå¯¦å€¼å’Œä¼°è¨ˆå€¼
    print("\nçœŸå¯¦å€¼èˆ‡ä¼°è¨ˆå€¼æ¯”è¼ƒ:")
    estimates = summary["mean"]
    
    # q å’Œ gamma çš„æ¯”è¼ƒ
    for param in ["q", "gamma"]:
        if param in estimates.index:
            true_val = true_params[param]
            est_val = estimates[param]
            error = abs(true_val - est_val)
            print(f"{param:>8}: çœŸå¯¦å€¼ = {true_val:>8.3f}, ä¼°è¨ˆå€¼ = {est_val:>8.3f}, èª¤å·® = {error:>8.3f}")
    
    # beta ä¿‚æ•¸çš„æ¯”è¼ƒ
    print("\nbeta ä¿‚æ•¸æ¯”è¼ƒ:")
    for i in range(num_covariates_X):
        param_name = f"beta[{i}]"
        if param_name in estimates.index:
            true_val = true_params["beta"][i]
            est_val = estimates[param_name]
            error = abs(true_val - est_val)
            print(f"{param_name:>10}: çœŸå¯¦å€¼ = {true_val:>8.3f}, ä¼°è¨ˆå€¼ = {est_val:>8.3f}, èª¤å·® = {error:>8.3f}")
    
    # theta ä¿‚æ•¸çš„æ¯”è¼ƒ  
    print("\ntheta ä¿‚æ•¸æ¯”è¼ƒ:")
    for i in range(num_covariates_x):
        param_name = f"theta[{i}]"
        if param_name in estimates.index:
            true_val = true_params["theta"][i]
            est_val = estimates[param_name]
            error = abs(true_val - est_val)
            print(f"{param_name:>10}: çœŸå¯¦å€¼ = {true_val:>8.3f}, ä¼°è¨ˆå€¼ = {est_val:>8.3f}, èª¤å·® = {error:>8.3f}")

    # å¾Œé©—åˆ†ä½ˆè¦–è¦ºåŒ–å’Œè¨ºæ–·
    visualize_posterior_distributions(trace_full_MCMC, "å®Œæ•´ Clog-log æ¨¡å‹", a_ij, prior_samples_full)
    generate_model_diagnostics(trace_full_MCMC, "å®Œæ•´ Clog-log æ¨¡å‹")

    print("\nå®Œæ•´ Clog-log æ¨¡å‹åŸ·è¡Œå®Œæˆï¼")

    # Fraction link æ¨¡å‹
    print("\né–‹å§‹ä¼°è¨ˆ Fraction link æ¨¡å‹...")
    fraction_link_model = build_fraction_link_model(s_ij, a_ij, X_ij, x_ij, coords)
    
    # è¦–è¦ºåŒ– Fraction link æ¨¡å‹çµæ§‹
    visualize_model_structure(fraction_link_model, "Fraction_link_æ¨¡å‹")
    analyze_model_structure(fraction_link_model, "Fraction link æ¨¡å‹")
    
    # å…ˆé©—é æ¸¬æ¡æ¨£
    prior_samples_fraction, _ = sample_and_visualize_prior_posterior(
        fraction_link_model, "Fraction link æ¨¡å‹", a_ij)
    
    with fraction_link_model:
        print("é–‹å§‹ Fraction link æ¨¡å‹ MCMC æ¡æ¨£...")
        trace_fraction_MCMC = pm.sample(
            draws=1000,
            tune=1000,
            chains=4,
            cores=min(4, multiprocessing.cpu_count()),
            target_accept=0.95,
            max_treedepth=12,
            init="adapt_diag",
            return_inferencedata=True,
            random_seed=123,
            progressbar=True
        )

    print("\nFraction link æ¨¡å‹åƒæ•¸ä¼°è¨ˆçµæœ:")
    summary_fraction = az.summary(trace_fraction_MCMC, var_names=["gamma", "beta", "theta"])
    print(summary_fraction)

    # æ¯”è¼ƒ Fraction link æ¨¡å‹çš„çœŸå¯¦å€¼å’Œä¼°è¨ˆå€¼
    print("\nFraction link æ¨¡å‹ - çœŸå¯¦å€¼èˆ‡ä¼°è¨ˆå€¼æ¯”è¼ƒ:")
    estimates_fraction = summary_fraction["mean"]
    
    # Fraction link æ¨¡å‹ä½¿ç”¨çš„çœŸå¯¦åƒæ•¸ï¼ˆä¸åŒ…å« qï¼‰
    true_params_fraction = {
        "gamma": true_params["gamma"],
        "beta": true_params["beta"], 
        "theta": true_params["theta"]
    }
    
    # gamma çš„æ¯”è¼ƒ
    if "gamma" in estimates_fraction.index:
        true_val = true_params_fraction["gamma"]
        est_val = estimates_fraction["gamma"]
        error = abs(true_val - est_val)
        print(f"{'gamma':>8}: çœŸå¯¦å€¼ = {true_val:>8.3f}, ä¼°è¨ˆå€¼ = {est_val:>8.3f}, èª¤å·® = {error:>8.3f}")
    
    # beta ä¿‚æ•¸çš„æ¯”è¼ƒ
    print("\nbeta ä¿‚æ•¸æ¯”è¼ƒ:")
    for i in range(num_covariates_X):
        param_name = f"beta[{i}]"
        if param_name in estimates_fraction.index:
            true_val = true_params_fraction["beta"][i]
            est_val = estimates_fraction[param_name]
            error = abs(true_val - est_val)
            print(f"{param_name:>10}: çœŸå¯¦å€¼ = {true_val:>8.3f}, ä¼°è¨ˆå€¼ = {est_val:>8.3f}, èª¤å·® = {error:>8.3f}")
    
    # theta ä¿‚æ•¸çš„æ¯”è¼ƒ  
    print("\ntheta ä¿‚æ•¸æ¯”è¼ƒ:")
    for i in range(num_covariates_x):
        param_name = f"theta[{i}]"
        if param_name in estimates_fraction.index:
            true_val = true_params_fraction["theta"][i]
            est_val = estimates_fraction[param_name]
            error = abs(true_val - est_val)
            print(f"{param_name:>10}: çœŸå¯¦å€¼ = {true_val:>8.3f}, ä¼°è¨ˆå€¼ = {est_val:>8.3f}, èª¤å·® = {error:>8.3f}")
    
    # å¾Œé©—åˆ†ä½ˆè¦–è¦ºåŒ–å’Œè¨ºæ–·
    visualize_posterior_distributions(trace_fraction_MCMC, "Fraction link æ¨¡å‹", a_ij, prior_samples_fraction)
    generate_model_diagnostics(trace_fraction_MCMC, "Fraction link æ¨¡å‹")

    print("\nFraction link æ¨¡å‹åŸ·è¡Œå®Œæˆï¼")

    # ========================= 4. æ¨¡å‹æ¯”è¼ƒèˆ‡è©•ä¼° =========================
    print("\n" + "="*60)
    print("æ¨¡å‹æ¯”è¼ƒèˆ‡è©•ä¼°")
    print("="*60)

    # WAIC æ¯”è¼ƒ
    try:
        waic_full = az.waic(trace_full_MCMC)
        waic_fraction = az.waic(trace_fraction_MCMC)
        
        print("\nWAIC æ¯”è¼ƒ (è¶Šå°è¶Šå¥½):")
        print(f"å®Œæ•´ Clog-log æ¨¡å‹: {waic_full.waic:.2f} Â± {waic_full.se:.2f}")
        print(f"Fraction link æ¨¡å‹: {waic_fraction.waic:.2f} Â± {waic_fraction.se:.2f}")
        
    except Exception as e:
        print(f"WAIC è¨ˆç®—å¤±æ•—: {e}")

    # é æ¸¬æº–ç¢ºæ€§è©•ä¼°
    print("\né æ¸¬æº–ç¢ºæ€§è©•ä¼°...")
    
    def calculate_prediction_accuracy(trace, model_name):
        """è¨ˆç®—é æ¸¬æº–ç¢ºæ€§"""
        try:
            # ç²å–å¾Œé©—é æ¸¬æ©Ÿç‡
            p_pred = trace.posterior["p_acceptance"].mean(dim=["chain", "draw"]).values
            
            # è½‰æ›ç‚ºé æ¸¬æ¨™ç±¤ (é–¾å€¼ = 0.5)
            a_pred = (p_pred > 0.5).astype(int)
            
            # è¨ˆç®—æº–ç¢ºç‡
            accuracy = np.mean(a_pred == a_ij)
            
            print(f"{model_name}: æº–ç¢ºç‡ = {accuracy:.3f}")
            return accuracy
            
        except Exception as e:
            print(f"{model_name} é æ¸¬è©•ä¼°å¤±æ•—: {e}")
            return None

    # è©•ä¼°å„æ¨¡å‹çš„é æ¸¬æ€§èƒ½
    accuracy_full = calculate_prediction_accuracy(trace_full_MCMC, "å®Œæ•´ Clog-log æ¨¡å‹")
    accuracy_fraction = calculate_prediction_accuracy(trace_fraction_MCMC, "Fraction link æ¨¡å‹")

    # ========================= 5. ADVI è®Šåˆ†æ¨è«– =========================
    print("\n" + "="*60)
    print("ADVI è®Šåˆ†æ¨è«–")
    print("="*60)

    def run_advi_inference(model, model_name, n_iterations=20000):
        """åŸ·è¡Œ ADVI è®Šåˆ†æ¨è«–"""
        print(f"é–‹å§‹ {model_name} ADVI æ¨è«–...")
        
        with model:
            try:
                # ä½¿ç”¨æ”¹é€²çš„ ADVI è¨­å®š
                approx = pm.fit(
                    method="advi", 
                    n=n_iterations,
                    random_seed=123,
                    progressbar=True,
                    obj_optimizer=pm.adagrad_window,  # ä½¿ç”¨ AdaGrad å„ªåŒ–å™¨
                    total_grad_norm_constraint=100   # æ¢¯åº¦è£å‰ª
                )
                
                # æª¢æŸ¥æ”¶æ–‚æ€§
                if hasattr(approx, 'hist'):
                    final_loss = approx.hist[-100:].mean()  # æœ€å¾Œ100æ¬¡è¿­ä»£çš„å¹³å‡æå¤±
                    print(f"   æœ€çµ‚ ELBO æå¤±: {final_loss:.2f}")
                
                # å¾è®Šåˆ†å¾Œé©—æ¡æ¨£
                trace_advi = approx.sample(
                    draws=1000, 
                    random_seed=123,
                    return_inferencedata=True
                )
                print(f"âœ“ {model_name} ADVI å®Œæˆ")
                return trace_advi
                
            except Exception as e:
                print(f"âœ— {model_name} ADVI å¤±æ•—: {e}")
                import traceback
                traceback.print_exc()
                return None

    # åŸ·è¡Œå„æ¨¡å‹çš„ ADVI æ¨è«–
    trace_full_ADVI = run_advi_inference(full_cloglog_model, "å®Œæ•´ Clog-log æ¨¡å‹")
    trace_fraction_ADVI = run_advi_inference(fraction_link_model, "Fraction link æ¨¡å‹")

    # ADVI çµæœæ¯”è¼ƒ
    if trace_full_ADVI is not None:
        print("\nå®Œæ•´ Clog-log æ¨¡å‹ ADVI çµæœ:")
        summary_full_advi = az.summary(trace_full_ADVI, var_names=scalar_params)
        print(summary_full_advi)

    if trace_fraction_ADVI is not None:
        print("\nFraction link æ¨¡å‹ ADVI çµæœ:")
        summary_fraction_advi = az.summary(trace_fraction_ADVI, var_names=["gamma", "beta", "theta"])
        print(summary_fraction_advi)

    # ========================= 6. ç¶œåˆçµæœåˆ†æ =========================
    print("\n" + "="*60)
    print("ç¶œåˆçµæœåˆ†æ")
    print("="*60)

    # åƒæ•¸ä¼°è¨ˆæ¯”è¼ƒ
    print("\nåƒæ•¸ä¼°è¨ˆæ¯”è¼ƒï¼ˆMCMC vs ADVIï¼‰:")
    
    def compare_mcmc_advi(mcmc_trace, advi_trace, param_list, model_name):
        """æ¯”è¼ƒ MCMC å’Œ ADVI çš„åƒæ•¸ä¼°è¨ˆ"""
        if advi_trace is None:
            print(f"{model_name}: ADVI å¤±æ•—ï¼Œç„¡æ³•æ¯”è¼ƒ")
            return
            
        print(f"\n{model_name}:")
        print("åƒæ•¸        MCMCå‡å€¼    ADVIå‡å€¼    å·®ç•°")
        print("-" * 45)
        
        mcmc_summary = az.summary(mcmc_trace, var_names=param_list, kind="stats")
        advi_summary = az.summary(advi_trace, var_names=param_list, kind="stats")
        
        for param in mcmc_summary.index:
            if param in advi_summary.index:
                mcmc_mean = mcmc_summary.loc[param, "mean"]
                advi_mean = advi_summary.loc[param, "mean"]
                diff = abs(mcmc_mean - advi_mean)
                print(f"{param:>10}  {mcmc_mean:>8.3f}  {advi_mean:>8.3f}  {diff:>8.3f}")

    # æ¯”è¼ƒå„æ¨¡å‹çš„ MCMC å’Œ ADVI çµæœ
    compare_mcmc_advi(trace_full_MCMC, trace_full_ADVI, scalar_params, "å®Œæ•´ Clog-log æ¨¡å‹")
    compare_mcmc_advi(trace_fraction_MCMC, trace_fraction_ADVI, ["gamma", "beta", "theta"], "Fraction link æ¨¡å‹")

    # ========================= 7. æ¨¡å‹çµæ§‹æ¯”è¼ƒç¸½çµ =========================
    print("\n" + "="*60)
    print("æ¨¡å‹çµæ§‹æ¯”è¼ƒç¸½çµ")
    print("="*60)
    
    print("\næ¨¡å‹æ¶æ§‹å·®ç•°åˆ†æ:")
    print("å®Œæ•´ Clog-log æ¨¡å‹:")
    print("  â€¢ åŒ…å«å½¢ç‹€åƒæ•¸ qï¼ˆä¼°è¨ˆå€¼ï¼‰")
    print("  â€¢ ä½¿ç”¨å®Œæ•´çš„ Clog-log éˆæ¥å‡½æ•¸")
    print("  â€¢ æ¥å—æ©Ÿç‡: P(a=1|s,x) = 1 - (c_ij/(c_ij + Ï„_ij*s_ij))^q")
    print("  â€¢ åƒæ•¸æ•¸é‡: 7å€‹ï¼ˆq, Î³, 3å€‹Î², 2å€‹Î¸ï¼‰")
    print("  â€¢ è¨ˆç®—è¤‡é›œåº¦: é«˜")
    
    print("\nFraction link æ¨¡å‹:")
    print("  â€¢ ç›´æ¥çš„æ¯”ç‡å½¢å¼éˆæ¥å‡½æ•¸")
    print("  â€¢ æ¥å—æ©Ÿç‡: P(a=1|s,x) = s_ij / (Î´_ij + Îº_ij)")
    print("  â€¢ Î´_ij = Î³ * exp(-X_ij^T * Î²), Îº_ij = exp(x_ij^T * Î¸)")
    print("  â€¢ åƒæ•¸æ•¸é‡: 6å€‹ï¼ˆÎ³, 3å€‹Î², 2å€‹Î¸ï¼‰")
    print("  â€¢ è¨ˆç®—è¤‡é›œåº¦: ä¸­ç­‰")

    
    print("\nè¦–è¦ºåŒ–çµæœç¸½è¦½:")
    
    # GraphViz æ¨¡å‹çµæ§‹åœ–
    if GRAPHVIZ_AVAILABLE:
        print("  âœ“ æ¨¡å‹çµæ§‹åœ– (GraphViz):")
        print("    â€¢ model_structure_å®Œæ•´_Clog-log_æ¨¡å‹.png")
        print("    â€¢ model_structure_Fraction_link_æ¨¡å‹.png")
        print("    â€¢ æ¸…æ¥šé¡¯ç¤ºè®Šæ•¸é–“çš„ä¾è³´é—œä¿‚")
    else:
        print("  âš ï¸ GraphViz ä¸å¯ç”¨ï¼Œè·³éæ¨¡å‹çµæ§‹åœ–")
    
    # å¾Œé©—åˆ†ä½ˆè¦–è¦ºåŒ–
    if MATPLOTLIB_AVAILABLE:
        print("\n  âœ“ å¾Œé©—åˆ†ä½ˆè¦–è¦ºåŒ– (ArviZ + Matplotlib):")
        print("    â€¢ posterior_distributions_*.png (åƒæ•¸å¾Œé©—åˆ†ä½ˆ)")
        print("    â€¢ mcmc_traces_*.png (MCMC è»Œè·¡åœ–)")
        print("    â€¢ prediction_comparison_*.png (é æ¸¬vsè§€æ¸¬æ¯”è¼ƒ)")
        print("    â€¢ prior_posterior_comparison_*.png (å…ˆé©—vså¾Œé©—)")
        print("    â€¢ energy_diagnostic_*.png (èƒ½é‡è¨ºæ–·)")
        print("    â€¢ åŒ…å«æ··æ·†çŸ©é™£ã€æº–ç¢ºç‡åˆ†æç­‰")
    else:
        print("  âš ï¸ Matplotlib ä¸å¯ç”¨ï¼Œè·³éå¾Œé©—åˆ†ä½ˆè¦–è¦ºåŒ–")
        print("    ğŸ“ å®‰è£æŒ‡ä»¤: pip install matplotlib")
    
    print("\n  è¦–è¦ºåŒ–åŠŸèƒ½èªªæ˜:")
    print("    â€¢ å…ˆé©—é æ¸¬æ¡æ¨£ï¼šé©—è­‰æ¨¡å‹çš„å…ˆé©—å‡è¨­")
    print("    â€¢ å¾Œé©—åˆ†ä½ˆåœ–ï¼šé¡¯ç¤ºåƒæ•¸çš„ä¸ç¢ºå®šæ€§")
    print("    â€¢ è»Œè·¡åœ–ï¼šæª¢æŸ¥ MCMC æ”¶æ–‚æ€§")
    print("    â€¢ é æ¸¬æ¯”è¼ƒï¼šè©•ä¼°æ¨¡å‹é æ¸¬æ€§èƒ½")
    print("    â€¢ èƒ½é‡è¨ºæ–·ï¼šæª¢æ¸¬æ¡æ¨£æ•ˆç‡å•é¡Œ")
    
    
    print("\n æ¨¡å‹æ€§èƒ½:")
    if accuracy_full is not None:
        print(f"- å®Œæ•´ Clog-log æ¨¡å‹æº–ç¢ºç‡: {accuracy_full:.3f}")
    if accuracy_fraction is not None:
        print(f"- Fraction link æ¨¡å‹æº–ç¢ºç‡: {accuracy_fraction:.3f}")

    # ========================= 8. è©³ç´°èª¤å·®æ¯”è¼ƒåˆ†æ =========================
    print("\n" + "="*60)
    print("è©³ç´°èª¤å·®æ¯”è¼ƒåˆ†æï¼šå®Œæ•´æ¨¡å‹ vs ç°¡åŒ–æ¨¡å‹")
    print("="*60)
    
    def calculate_parameter_errors(trace, true_params, model_name):
        """è¨ˆç®—åƒæ•¸ä¼°è¨ˆèª¤å·®"""
        print(f"\n{model_name} åƒæ•¸ä¼°è¨ˆèª¤å·®åˆ†æ:")
        print("-" * 50)
        
        # ç²å–åƒæ•¸ä¼°è¨ˆå€¼
        summary = az.summary(trace, kind="stats")
        
        # å„²å­˜èª¤å·®çµæœ
        errors = {}
        
        # æª¢æŸ¥æ¯å€‹åƒæ•¸çš„èª¤å·®
        for param_name, true_value in true_params.items():
            if isinstance(true_value, (int, float)):
                # æ¨™é‡åƒæ•¸
                if param_name in summary.index:
                    estimated_value = summary.loc[param_name, "mean"]
                    absolute_error = abs(true_value - estimated_value)
                    relative_error = absolute_error / abs(true_value) * 100 if true_value != 0 else float('inf')
                    
                    errors[param_name] = {
                        'true': true_value,
                        'estimated': estimated_value,
                        'absolute_error': absolute_error,
                        'relative_error': relative_error
                    }
                    
                    print(f"{param_name:>8}: çœŸå¯¦å€¼={true_value:>8.3f}, ä¼°è¨ˆå€¼={estimated_value:>8.3f}")
                    print(f"{'':>8}  çµ•å°èª¤å·®={absolute_error:>8.3f}, ç›¸å°èª¤å·®={relative_error:>7.2f}%")
                else:
                    print(f"{param_name:>8}: æœªåœ¨æ¨¡å‹ä¸­ä¼°è¨ˆ")
                    
            elif isinstance(true_value, np.ndarray):
                # å‘é‡åƒæ•¸
                param_errors = []
                print(f"{param_name} å‘é‡åƒæ•¸:")
                
                for i, true_val in enumerate(true_value):
                    param_key = f"{param_name}[{i}]"
                    if param_key in summary.index:
                        estimated_val = summary.loc[param_key, "mean"]
                        absolute_error = abs(true_val - estimated_val)
                        relative_error = absolute_error / abs(true_val) * 100 if true_val != 0 else float('inf')
                        
                        param_errors.append({
                            'true': true_val,
                            'estimated': estimated_val,
                            'absolute_error': absolute_error,
                            'relative_error': relative_error
                        })
                        
                        print(f"  {param_key:>10}: çœŸå¯¦å€¼={true_val:>8.3f}, ä¼°è¨ˆå€¼={estimated_val:>8.3f}")
                        print(f"  {'':>10}  çµ•å°èª¤å·®={absolute_error:>8.3f}, ç›¸å°èª¤å·®={relative_error:>7.2f}%")
                    else:
                        print(f"  {param_key:>10}: æœªåœ¨æ¨¡å‹ä¸­ä¼°è¨ˆ")
                
                errors[param_name] = param_errors
        
        return errors
    
    # è¨ˆç®—å…©å€‹æ¨¡å‹çš„èª¤å·®
    errors_full = calculate_parameter_errors(trace_full_MCMC, true_params, "å®Œæ•´ Clog-log æ¨¡å‹")
    
    # Fraction link æ¨¡å‹çš„çœŸå¯¦åƒæ•¸ï¼ˆä¸åŒ…å« qï¼‰
    true_params_fraction = {
        "gamma": true_params["gamma"],
        "beta": true_params["beta"],
        "theta": true_params["theta"]
    }
    errors_fraction = calculate_parameter_errors(trace_fraction_MCMC, true_params_fraction, "Fraction link æ¨¡å‹")
    
    # ========================= èª¤å·®æ¯”è¼ƒç¸½çµ =========================
    print("\n" + "="*60)
    print("èª¤å·®æ¯”è¼ƒç¸½çµ")
    print("="*60)
    
    print("\nå…±åŒåƒæ•¸èª¤å·®æ¯”è¼ƒ:")
    print("åƒæ•¸åç¨±        å®Œæ•´æ¨¡å‹èª¤å·®    Fractionæ¨¡å‹èª¤å·®    èª¤å·®å·®ç•°")
    print("-" * 70)
    
    # æ¯”è¼ƒå…±åŒåƒæ•¸
    total_error_full = 0
    total_error_fraction = 0
    param_count = 0
    
    for param_name in ["gamma", "beta", "theta"]:
        if param_name in errors_full and param_name in errors_fraction:
            if isinstance(errors_full[param_name], dict):
                # æ¨™é‡åƒæ•¸
                error_full = errors_full[param_name]['absolute_error']
                error_fraction = errors_fraction[param_name]['absolute_error']
                error_diff = error_full - error_fraction
                
                total_error_full += error_full
                total_error_fraction += error_fraction
                param_count += 1
                
                print(f"{param_name:>12}     {error_full:>8.3f}           {error_fraction:>8.3f}     {error_diff:>+8.3f}")
                
            elif isinstance(errors_full[param_name], list):
                # å‘é‡åƒæ•¸
                for i, (err_full, err_fraction) in enumerate(zip(errors_full[param_name], errors_fraction[param_name])):
                    error_full = err_full['absolute_error']
                    error_fraction = err_fraction['absolute_error']
                    error_diff = error_full - error_fraction
                    
                    total_error_full += error_full
                    total_error_fraction += error_fraction
                    param_count += 1
                    
                    param_label = f"{param_name}[{i}]"
                    print(f"{param_label:>12}     {error_full:>8.3f}           {error_fraction:>8.3f}     {error_diff:>+8.3f}")
    
    print("-" * 70)
    avg_error_full = total_error_full / param_count if param_count > 0 else 0
    avg_error_fraction = total_error_fraction / param_count if param_count > 0 else 0
    
    print(f"{'å¹³å‡èª¤å·®':>12}     {avg_error_full:>8.3f}           {avg_error_fraction:>8.3f}     {avg_error_full - avg_error_fraction:>+8.3f}")
    
    # ========================= ç‰¹æœ‰åƒæ•¸åˆ†æ =========================
    print(f"\nå®Œæ•´æ¨¡å‹ç‰¹æœ‰åƒæ•¸ (q):")
    if "q" in errors_full:
        q_error = errors_full["q"]
        print(f"  q åƒæ•¸: çœŸå¯¦å€¼={q_error['true']:.3f}, ä¼°è¨ˆå€¼={q_error['estimated']:.3f}")
        print(f"         çµ•å°èª¤å·®={q_error['absolute_error']:.3f}, ç›¸å°èª¤å·®={q_error['relative_error']:.2f}%")
    
    # ========================= æ¨¡å‹é¸æ“‡å»ºè­° =========================
    print(f"\nğŸ¯ æ¨¡å‹é¸æ“‡å»ºè­°:")
    print("-" * 40)
    
    if avg_error_full < avg_error_fraction:
        print("âœ… å®Œæ•´ Clog-log æ¨¡å‹è¡¨ç¾è¼ƒä½³")
        print(f"   â€¢ å¹³å‡çµ•å°èª¤å·®æ›´ä½: {avg_error_full:.3f} vs {avg_error_fraction:.3f}")
        print(f"   â€¢ èª¤å·®æ”¹å–„: {((avg_error_fraction - avg_error_full) / avg_error_fraction * 100):.1f}%")
        better_model = "å®Œæ•´æ¨¡å‹"
    elif avg_error_fraction < avg_error_full:
        print("âœ… Fraction link æ¨¡å‹è¡¨ç¾è¼ƒä½³")
        print(f"   â€¢ å¹³å‡çµ•å°èª¤å·®æ›´ä½: {avg_error_fraction:.3f} vs {avg_error_full:.3f}")
        print(f"   â€¢ èª¤å·®æ”¹å–„: {((avg_error_full - avg_error_fraction) / avg_error_full * 100):.1f}%")
        better_model = "Fractionæ¨¡å‹"
    else:
        print("âš–ï¸ å…©å€‹æ¨¡å‹è¡¨ç¾ç›¸ç•¶")
        print(f"   â€¢ å¹³å‡çµ•å°èª¤å·®ç›¸è¿‘: {avg_error_full:.3f} â‰ˆ {avg_error_fraction:.3f}")
        better_model = "ç›¸ç•¶"
    
  
    
    print("\nğŸ“ˆ å¯¦è­‰çµæœç¸½çµ:")
    print("-" * 50)
    
    # ç¸½çµæ¨¡å‹æ€§èƒ½
    if accuracy_full is not None and accuracy_fraction is not None:
        performance_diff = accuracy_full - accuracy_fraction
        print(f"é æ¸¬æº–ç¢ºç‡:")
        print(f"  â€¢ å®Œæ•´ Clog-log æ¨¡å‹: {accuracy_full:.3f}")
        print(f"  â€¢ Fraction link æ¨¡å‹: {accuracy_fraction:.3f}")
        print(f"  â€¢ æº–ç¢ºç‡å·®ç•°: {performance_diff:+.3f}")
        
        if abs(performance_diff) < 0.01:
            print(f"  â†’ å…©ç¨®æ¨¡å‹é æ¸¬æ€§èƒ½ç›¸ç•¶")
        elif performance_diff > 0:
            print(f"  â†’ Clog-log æ¨¡å‹é æ¸¬ç¨ä½³")
        else:
            print(f"  â†’ Fraction link æ¨¡å‹é æ¸¬ç¨ä½³")
    
    print(f"\nåƒæ•¸ä¼°è¨ˆç²¾åº¦:")
    if 'avg_error_full' in locals() and 'avg_error_fraction' in locals():
        error_improvement = ((max(avg_error_full, avg_error_fraction) - min(avg_error_full, avg_error_fraction)) 
                            / max(avg_error_full, avg_error_fraction) * 100)
        
        if avg_error_full < avg_error_fraction:
            print(f"  â€¢ Clog-log æ¨¡å‹ä¼°è¨ˆç²¾åº¦æ›´é«˜")
            print(f"  â€¢ ç²¾åº¦æ”¹å–„: {error_improvement:.1f}%")
        elif avg_error_fraction < avg_error_full:
            print(f"  â€¢ Fraction link æ¨¡å‹ä¼°è¨ˆç²¾åº¦æ›´é«˜") 
            print(f"  â€¢ ç²¾åº¦æ”¹å–„: {error_improvement:.1f}%")
        else:
            print(f"  â€¢ å…©ç¨®æ¨¡å‹ä¼°è¨ˆç²¾åº¦ç›¸ç•¶")
    
    
