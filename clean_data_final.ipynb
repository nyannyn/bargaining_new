{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 載入資料並確認thread_id 符合定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 刪除 src_cre_date 重複的組別後，( item_id,byr_id,slr_id ) 無論是否唯一，都只會對應到唯一一個thread<br>\n",
    "> 上述刪除採用cascate (只要找到一筆，則整組( item_id,byr_id,slr_id )一同刪除 )<br>\n",
    "> =>為甚麼不是distinct ? 因為用 src_cre_date 刪除更為嚴格也符合常理\n",
    "> 僅有少數組資料記錄錯誤，因此將其刪除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始資料筆數: 47377200\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "pl_df = pl.read_csv(r'C:\\Users\\ChenChun\\Downloads\\bargaining_data\\anon_bo_threads.csv'); \n",
    "\n",
    "original_count = pl_df.shape[0]\n",
    "print(f'初始資料筆數: {pl_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChenChun\\AppData\\Local\\Temp\\ipykernel_8336\\3172605028.py:5: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  .agg(pl.count().alias(\"count\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 重複 src_cre_date 的原始資料範例（前 5 筆）：\n",
      "shape: (5, 8)\n",
      "┌────────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ anon_slr_i ┆ anon_byr_i ┆ anon_item_ ┆ anon_thre ┆ src_cre_d ┆ offr_type ┆ status_id ┆ response_ │\n",
      "│ d          ┆ d          ┆ id         ┆ ad_id     ┆ ate       ┆ _id       ┆ ---       ┆ time      │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ ---       ┆ ---       ┆ ---       ┆ i64       ┆ ---       │\n",
      "│ i64        ┆ i64        ┆ i64        ┆ i64       ┆ str       ┆ i64       ┆           ┆ str       │\n",
      "╞════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 1395337    ┆ 6282576    ┆ 76566287   ┆ 4376595   ┆ 18jul2013 ┆ 0         ┆ 2         ┆ 18jul2013 │\n",
      "│            ┆            ┆            ┆           ┆ 08:52:26  ┆           ┆           ┆ 09:34:53  │\n",
      "│ 1395337    ┆ 6282576    ┆ 76566287   ┆ 4376595   ┆ 18jul2013 ┆ 0         ┆ 2         ┆ 18jul2013 │\n",
      "│            ┆            ┆            ┆           ┆ 08:52:26  ┆           ┆           ┆ 09:34:53  │\n",
      "│ 9710114    ┆ 6965971    ┆ 38002151   ┆ 1872632   ┆ 22dec2012 ┆ 0         ┆ 6         ┆ 22dec2012 │\n",
      "│            ┆            ┆            ┆           ┆ 15:53:17  ┆           ┆           ┆ 15:53:17  │\n",
      "│ 9710114    ┆ 6965971    ┆ 38002151   ┆ 1122609   ┆ 22dec2012 ┆ 0         ┆ 6         ┆ 22dec2012 │\n",
      "│            ┆            ┆            ┆           ┆ 15:53:17  ┆           ┆           ┆ 15:53:17  │\n",
      "│ 10465916   ┆ 3823425    ┆ 17465281   ┆ 9699247   ┆ 26dec2012 ┆ 0         ┆ 6         ┆ 26dec2012 │\n",
      "│            ┆            ┆            ┆           ┆ 07:12:17  ┆           ┆           ┆ 07:12:17  │\n",
      "└────────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┴───────────┘\n",
      "刪除整組（因 src_cre_date 重複）之筆數: 15739\n"
     ]
    }
   ],
   "source": [
    "# 找出 src_cre_date 完全重複的組合（賣家+買家+商品+時間）\n",
    "dup_keys = (\n",
    "    pl_df\n",
    "    .group_by(['anon_slr_id', 'anon_byr_id', 'anon_item_id', 'src_cre_date'])\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    "    .filter(pl.col(\"count\") > 1)\n",
    "    .select(['anon_slr_id', 'anon_byr_id', 'anon_item_id', 'src_cre_date'])\n",
    ")\n",
    "\n",
    "# Step 3：找出所有屬於這些重複行的原始資料\n",
    "duplicated_rows = pl_df.join(\n",
    "    dup_keys,\n",
    "    on=['anon_slr_id', 'anon_byr_id', 'anon_item_id', 'src_cre_date'],\n",
    "    how='inner'\n",
    ")\n",
    "# 印出範例資料（前 5 筆）\n",
    "print(\"========== 重複 src_cre_date 的原始資料範例（前 5 筆）：\")\n",
    "print(duplicated_rows.select([\n",
    "    'anon_slr_id', 'anon_byr_id', 'anon_item_id','anon_thread_id' , 'src_cre_date','offr_type_id','status_id','response_time'\n",
    "]).head(5))\n",
    "\n",
    "# Step 4：從這些 row 找出該整組的 item group（不含時間）\n",
    "groups_to_remove = duplicated_rows.select([\n",
    "    'anon_slr_id', 'anon_byr_id', 'anon_item_id'\n",
    "]).unique()\n",
    "\n",
    "# Step 5：從原始 df 中刪掉整組 group\n",
    "df_cleaned = pl_df.join(\n",
    "    groups_to_remove,\n",
    "    on=['anon_slr_id', 'anon_byr_id', 'anon_item_id'],\n",
    "    how='anti'\n",
    ")\n",
    "\n",
    "# Step 6：統計刪除筆數\n",
    "deleted_rows_count = original_count - df_cleaned.shape[0]\n",
    "print(\"刪除整組（因 src_cre_date 重複）之筆數:\", deleted_rows_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuwenhsuuu\\anaconda3\\lib\\functools.py:889: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共刪除 15 筆例外資料（這些組別沒有唯一的 thread_id）\n",
      "====================================\n",
      "目前的資料筆數:  47361446\n"
     ]
    }
   ],
   "source": [
    "# 先記錄原始筆數\n",
    "original_count = df_cleaned.shape[0]\n",
    "\n",
    "# ---------------------\n",
    "# 第一段：精準條件刪除 (包含 item_id, thread_id, byr_id, slr_id)\n",
    "# ---------------------\n",
    "to_delete = [\n",
    "    (58639544, 8655052, 5712605, 3943399),\n",
    "    (58639544, 1632051, 5712605, 3943399),\n",
    "    (2773744, 7212858, 1689684, 5718581),\n",
    "    (2773744, 3721458, 1689684, 5718581),\n",
    "]\n",
    "\n",
    "# 轉成 Polars 的條件過濾邏輯\n",
    "for item_id, thread_id, byr_id, slr_id in to_delete:\n",
    "    df_cleaned = df_cleaned.filter(~(\n",
    "        (pl.col(\"anon_item_id\") == item_id) &\n",
    "        (pl.col(\"anon_thread_id\") == thread_id) &\n",
    "        (pl.col(\"anon_byr_id\") == byr_id) &\n",
    "        (pl.col(\"anon_slr_id\") == slr_id)\n",
    "    ))\n",
    "\n",
    "# ---------------------\n",
    "# 第二段：以 (slr_id, byr_id, item_id) 為 key 刪除整組\n",
    "# ---------------------\n",
    "search_conditions = [\n",
    "    (805737, 3547513, 9145419),\n",
    "    (4667211, 8350361, 40000809),\n",
    "    (7773303, 3771453, 47886959),\n",
    "    (7927663, 3576898, 67593548),\n",
    "    (9211073, 9334414, 88204993),\n",
    "    (9537923, 7605857, 40868572),\n",
    "    (10176360, 8235394, 59174743),\n",
    "]\n",
    "\n",
    "# 建立要刪除的組合 DataFrame\n",
    "conditions_df = pl.DataFrame(search_conditions, schema=[\"anon_slr_id\", \"anon_byr_id\", \"anon_item_id\"])\n",
    "\n",
    "# 使用 anti join 刪除這些 group\n",
    "df_cleaned = df_cleaned.join(\n",
    "    conditions_df,\n",
    "    on=[\"anon_slr_id\", \"anon_byr_id\", \"anon_item_id\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# ---------------------\n",
    "# 印出結果\n",
    "# ---------------------\n",
    "deleted_count = original_count - df_cleaned.shape[0]\n",
    "print(\"共刪除\", deleted_count, \"筆例外資料（這些組別沒有唯一的 thread_id）\")\n",
    "print(\"====================================\")\n",
    "print(\"目前的資料筆數: \", df_cleaned.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 檢查上述程式碼是否執行正確\n",
    "> 檢查 groupby(slr, byr, item) 後的資料是否僅有唯一 thread_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 所有組合的 thread_id 都是唯一的。\n"
     ]
    }
   ],
   "source": [
    "# 針對每組 (slr_id, byr_id, item_id) 統計 thread_id 的不重複數量\n",
    "grouped = (\n",
    "    df_cleaned\n",
    "    .group_by(['anon_slr_id', 'anon_byr_id', 'anon_item_id'])\n",
    "    .agg(pl.col('anon_thread_id').n_unique().alias('thread_id_count'))\n",
    ")\n",
    "\n",
    "# 篩選出 thread_id 不唯一的組\n",
    "non_unique_threads = grouped.filter(pl.col('thread_id_count') > 1)\n",
    "\n",
    "# 印出結果\n",
    "if non_unique_threads.is_empty():\n",
    "    print(\"✅ 所有組合的 thread_id 都是唯一的。\")\n",
    "else:\n",
    "    print(\"⚠️ 以下組合的 thread_id 不唯一：\")\n",
    "    print(non_unique_threads)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.填值 \n",
    "買賣雙方針對商品產生的討論串中，有些欄位的值只會出現在第一筆<br>\n",
    "例如: groupby(slr, byr, item, thread)， slr_hist/byr_hist/byr_us 正確的值僅存於組內排序後的第一筆資料(用src_cre_date排序，而非offr_type_id==0)，所以要先做填值，才能做資料清理([ppt第三十頁](https://docs.google.com/presentation/d/1b9MVElz9fjTnk3c-D-jzDurlGD0HzqPzE8fCyvo7NDI/edit#slide=id.g33877aea87e_0_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **注意:正確排序需要先將字串轉換為日期時間格式**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.with_columns([\n",
    "    pl.col(\"src_cre_date\").str.strptime(pl.Datetime, format=\"%d%b%Y %H:%M:%S\").alias(\"src_cre_date\"),\n",
    "    pl.col(\"response_time\").filter(pl.col(\"response_time\").is_not_null())\n",
    "      .str.strptime(pl.Datetime, format=\"%d%b%Y %H:%M:%S\").alias(\"response_time\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 先群組並組內排序 : <br>\n",
    "> 1. 檢查組內第一筆資料使否offer_type_id ==0\n",
    "> 2. 檢查補值欄位 'slr_hist', 'byr_hist', 'byr_us' 是否為空值\n",
    "> 3. 發現 slr_hist 具空值欄位 僅組內一筆資料時，將 null值補 0 (因為slr_hist最小為1)\n",
    "> 4. 填值: 用組內排序後的第一筆資料(用src_cre_date排序，而非offr_type_id==0)，做填值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47361446"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "offr_type_id != 0 的第一筆資料有 0 筆\n",
      "\n",
      "第一筆資料的空值檢查結果:\n",
      "shape: (1, 4)\n",
      "┌────────────┬─────────────────────┬─────────────────────┬───────────────────┐\n",
      "│ 總資料筆數 ┆ slr_hist_null_count ┆ byr_hist_null_count ┆ byr_us_null_count │\n",
      "│ ---        ┆ ---                 ┆ ---                 ┆ ---               │\n",
      "│ i32        ┆ u32                 ┆ u32                 ┆ u32               │\n",
      "╞════════════╪═════════════════════╪═════════════════════╪═══════════════════╡\n",
      "│ 28197270   ┆ 840080              ┆ 0                   ┆ 0                 │\n",
      "└────────────┴─────────────────────┴─────────────────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# 欲補值欄位\n",
    "cols_to_fill = ['slr_hist', 'byr_hist', 'byr_us']  # 定義需要填補的欄位\n",
    "group_keys = ['anon_slr_id', 'anon_byr_id', 'anon_item_id', 'anon_thread_id']  # 定義分組的鍵值\n",
    "\n",
    "\n",
    "# 先排序，然後添加行號\n",
    "df_ranked = (\n",
    "    df_cleaned  # 包含日期時間格式的資料框\n",
    "    .sort(group_keys + [\"src_cre_date\"])  # 依照群組鍵和時間排序\n",
    "    .with_columns([\n",
    "        pl.col(\"offr_type_id\"),\n",
    "        *[pl.col(col) for col in cols_to_fill],\n",
    "        # 使用over()函數在每個群組中創建排名\n",
    "        pl.col(\"src_cre_date\").rank(\"dense\").over(group_keys).alias(\"row_num\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "#  ======== 1. 檢查組內第一筆資料使否offer_type_id ==0 \n",
    "df_first_rows = df_ranked.filter(pl.col(\"row_num\") == 1)  # 篩選出每個群組的第一筆資料\n",
    "df_offr_not_zero = df_first_rows.filter(pl.col(\"offr_type_id\") != 0)  # 找出不符合預期的第一筆（非買家出價）\n",
    "count_offr_not_zero = df_offr_not_zero.shape[0]  # 計算這類例外資料的數量\n",
    "print(f\"\\noffr_type_id != 0 的第一筆資料有 {count_offr_not_zero} 筆\")\n",
    "\n",
    "#  ======== 2. 檢查補值欄位 'slr_hist', 'byr_hist', 'byr_us' 是否為空值\n",
    "null_check = df_first_rows.select([\n",
    "    pl.lit(df_first_rows.shape[0]).alias(\"總資料筆數\"),# 計算總共有多少個第一筆資料\n",
    "    \n",
    "    # 檢查每個欄位是否有 null\n",
    "    pl.col(\"slr_hist\").is_null().sum().alias(\"slr_hist_null_count\"),\n",
    "    pl.col(\"byr_hist\").is_null().sum().alias(\"byr_hist_null_count\"),\n",
    "    pl.col(\"byr_us\").is_null().sum().alias(\"byr_us_null_count\"),\n",
    "    \n",
    "])\n",
    "\n",
    "print(\"\\n第一筆資料的空值檢查結果:\")\n",
    "print(null_check)\n",
    "\n",
    "# # 印出第一筆資料中slr_hist為空的前幾筆記錄\n",
    "# null_slr_hist_first = df_first_rows.filter(pl.col(\"slr_hist\").is_null())\n",
    "# print(\"\\nslr_hist為空的第一筆資料 (前5筆):\")\n",
    "# print(null_slr_hist_first.select(group_keys + [\"src_cre_date\", \"slr_hist\", \"offr_type_id\"]).head(5))\n",
    "\n",
    "\n",
    "# 將 slr_hist為null的資料 填補 0\n",
    "df_cleaned_filled = df_ranked.with_columns(\n",
    "    pl.when(pl.col(\"slr_hist\").is_null() & (pl.col(\"row_num\") == 1)) # 檢查每一筆資料中的slr_hist欄位是否為空值，是否為其所屬群組的第一筆資料（row_num == 1）\n",
    "      .then(pl.lit(0))\n",
    "      .otherwise(pl.col(\"slr_hist\"))\n",
    "      .alias(\"slr_hist\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 檢查第一筆資料 slr_hist、byr_hist、byr_us 三欄位的分布\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一筆三欄位空值情況：\n",
      "shape: (1, 4)\n",
      "┌────────────┬─────────────────────┬─────────────────────┬───────────────────┐\n",
      "│ 總資料筆數 ┆ slr_hist_null_count ┆ byr_hist_null_count ┆ byr_us_null_count │\n",
      "│ ---        ┆ ---                 ┆ ---                 ┆ ---               │\n",
      "│ i32        ┆ u32                 ┆ u32                 ┆ u32               │\n",
      "╞════════════╪═════════════════════╪═════════════════════╪═══════════════════╡\n",
      "│ 28197270   ┆ 0                   ┆ 0                   ┆ 0                 │\n",
      "└────────────┴─────────────────────┴─────────────────────┴───────────────────┘\n",
      "第一筆資料三欄位的基本統計：\n",
      "shape: (1, 4)\n",
      "┌────────────┬─────────────────┬─────────────────┬───────────────┐\n",
      "│ 總資料筆數 ┆ slr_hist_平均值 ┆ byr_hist_平均值 ┆ byr_us_平均值 │\n",
      "│ ---        ┆ ---             ┆ ---             ┆ ---           │\n",
      "│ i32        ┆ f64             ┆ f64             ┆ f64           │\n",
      "╞════════════╪═════════════════╪═════════════════╪═══════════════╡\n",
      "│ 28197270   ┆ 3746.670963     ┆ 132.362123      ┆ 0.873565      │\n",
      "└────────────┴─────────────────┴─────────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_first_rows = df_cleaned_filled.filter(pl.col(\"row_num\") == 1)  # 篩選出每個群組的第一筆資料\n",
    "null_check_after = df_first_rows.select([\n",
    "    pl.lit(df_first_rows.shape[0]).alias(\"總資料筆數\"),\n",
    "    pl.col(\"slr_hist\").is_null().sum().alias(\"slr_hist_null_count\"),\n",
    "    pl.col(\"byr_hist\").is_null().sum().alias(\"byr_hist_null_count\"),\n",
    "    pl.col(\"byr_us\").is_null().sum().alias(\"byr_us_null_count\")\n",
    "])\n",
    "\n",
    "print(\"第一筆三欄位空值情況：\")\n",
    "print(null_check_after)\n",
    "\n",
    "# 計算三個欄位的基本統計量\n",
    "stats_first_rows = df_first_rows.select([\n",
    "    pl.lit(df_first_rows.shape[0]).alias(\"總資料筆數\"),\n",
    "    \n",
    "    # slr_hist 統計\n",
    "    pl.col(\"slr_hist\").mean().alias(\"slr_hist_平均值\"),\n",
    "    # pl.col(\"slr_hist\").median().alias(\"slr_hist_中位數\"),\n",
    "    # pl.col(\"slr_hist\").min().alias(\"slr_hist_最小值\"),\n",
    "    # pl.col(\"slr_hist\").max().alias(\"slr_hist_最大值\"),\n",
    "    # pl.col(\"slr_hist\").std().alias(\"slr_hist_標準差\"),\n",
    "    \n",
    "    # byr_hist 統計\n",
    "    pl.col(\"byr_hist\").mean().alias(\"byr_hist_平均值\"),\n",
    "    # pl.col(\"byr_hist\").median().alias(\"byr_hist_中位數\"),\n",
    "    # pl.col(\"byr_hist\").min().alias(\"byr_hist_最小值\"),\n",
    "    # pl.col(\"byr_hist\").max().alias(\"byr_hist_最大值\"),\n",
    "    # pl.col(\"byr_hist\").std().alias(\"byr_hist_標準差\"),\n",
    "    \n",
    "    # byr_us 統計\n",
    "    pl.col(\"byr_us\").mean().alias(\"byr_us_平均值\"),\n",
    "    # pl.col(\"byr_us\").median().alias(\"byr_us_中位數\"),\n",
    "    # pl.col(\"byr_us\").min().alias(\"byr_us_最小值\"),\n",
    "    # pl.col(\"byr_us\").max().alias(\"byr_us_最大值\"),\n",
    "    # pl.col(\"byr_us\").std().alias(\"byr_us_標準差\")\n",
    "])\n",
    "\n",
    "print(\"第一筆資料三欄位的基本統計：\")\n",
    "print(stats_first_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 用組內排序後第一筆資料對組內後續資料作填值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "填充後的空值檢查結果:\n",
      "shape: (1, 4)\n",
      "┌────────────┬─────────────────────┬─────────────────────┬───────────────────┐\n",
      "│ 總資料筆數 ┆ slr_hist_null_count ┆ byr_hist_null_count ┆ byr_us_null_count │\n",
      "│ ---        ┆ ---                 ┆ ---                 ┆ ---               │\n",
      "│ i32        ┆ u32                 ┆ u32                 ┆ u32               │\n",
      "╞════════════╪═════════════════════╪═════════════════════╪═══════════════════╡\n",
      "│ 47361446   ┆ 0                   ┆ 0                   ┆ 0                 │\n",
      "└────────────┴─────────────────────┴─────────────────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# 用組內排序後第一筆資料對組內後續資料作填值\n",
    "\n",
    "# 先獲取每個群組的第一筆資料\n",
    "first_values_per_group = df_cleaned_filled.filter(pl.col(\"row_num\") == 1).select([\n",
    "    *group_keys,  # 群組鍵\n",
    "    pl.col(\"slr_hist\").alias(\"first_slr_hist\"),\n",
    "    pl.col(\"byr_hist\").alias(\"first_byr_hist\"),\n",
    "    pl.col(\"byr_us\").alias(\"first_byr_us\")\n",
    "])\n",
    "\n",
    "# 將第一筆資料與原始數據連接\n",
    "df_with_first = df_cleaned_filled.join(\n",
    "    first_values_per_group,\n",
    "    on=group_keys,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 使用第一筆資料填充空值 (為所有組內資料)\n",
    "df_filled = df_with_first.with_columns([\n",
    "    # 若slr_hist為空，則使用該組第一筆的值\n",
    "    pl.when(pl.col(\"slr_hist\").is_null())\n",
    "      .then(pl.col(\"first_slr_hist\"))\n",
    "      .otherwise(pl.col(\"slr_hist\"))\n",
    "      .alias(\"slr_hist\"),\n",
    "    \n",
    "    # 若byr_hist為空，則使用該組第一筆的值\n",
    "    pl.when(pl.col(\"byr_hist\").is_null())\n",
    "      .then(pl.col(\"first_byr_hist\"))\n",
    "      .otherwise(pl.col(\"byr_hist\"))\n",
    "      .alias(\"byr_hist\"),\n",
    "    \n",
    "    # byr_us欄位直接用第一筆資料覆蓋所有資料\n",
    "    pl.col(\"first_byr_us\").alias(\"byr_us\")\n",
    "])\n",
    "\n",
    "# 移除臨時列\n",
    "df_filled_final = df_filled.drop([\"first_slr_hist\", \"first_byr_hist\", \"first_byr_us\"])\n",
    "\n",
    "\n",
    "# 檢查填充後是否還有空值\n",
    "null_check_after = df_filled_final.select([\n",
    "    pl.lit(df_filled_final.shape[0]).alias(\"總資料筆數\"),\n",
    "    # pl.col(\"first_slr_hist\").is_null().sum().alias(\"new_slr_hist_null_count\"),\n",
    "    pl.col(\"slr_hist\").is_null().sum().alias(\"slr_hist_null_count\"),\n",
    "    # pl.col(\"first_byr_hist\").is_null().sum().alias(\"new_byr_hist_null_count\"),\n",
    "    pl.col(\"byr_hist\").is_null().sum().alias(\"byr_hist_null_count\"),\n",
    "    # pl.col(\"first_byr_us\").is_null().sum().alias(\"new_byr_us_null_count\"),\n",
    "    pl.col(\"byr_us\").is_null().sum().alias(\"byr_us_null_count\")\n",
    "])\n",
    "\n",
    "print(\"\\n填充後的空值檢查結果:\")\n",
    "print(null_check_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 篩出 同一買賣家 在相近時間(48hr內)談判不同商品"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 確認 src_cre_date 和 response_time 為 datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_cre_date的數據類型：Datetime(time_unit='us', time_zone=None)\n",
      "response_time的數據類型：Datetime(time_unit='us', time_zone=None)\n"
     ]
    }
   ],
   "source": [
    "src_cre_date_type = df_filled_final.select(pl.col(\"src_cre_date\")).dtypes[0]\n",
    "response_time_type = df_filled_final.select(pl.col(\"response_time\")).dtypes[0]\n",
    "\n",
    "print(f\"src_cre_date的數據類型：{src_cre_date_type}\")\n",
    "print(f\"response_time的數據類型：{response_time_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 排序 -> 計算相鄰兩筆資料的時間差 -> 標註相鄰兩筆48hr內資料overlap -> 將被標註過的組移出 df -> 存進\"整理.csv\"、\"被刪除.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_overlap_window(df: pl.DataFrame, buffer: int = 1) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    顯示所有 final_overlap = 1 的紀錄，並包含前後 buffer 筆資料，用來人工檢查 overlap 標註是否正確。\n",
    "    \n",
    "    參數：\n",
    "        df     : 已經有 final_overlap 欄位的資料表\n",
    "        buffer : 要顯示多少前後相鄰紀錄（預設為 1）\n",
    "\n",
    "    回傳：\n",
    "        pl.DataFrame：包含 overlap 區段前後紀錄的子集（已去除重複）\n",
    "    \"\"\"\n",
    "    # 加入群內排序編號\n",
    "    df_debug = df.with_columns([\n",
    "        pl.arange(0, pl.count()).over([\"anon_slr_id\", \"anon_byr_id\"]).alias(\"row_in_group\")\n",
    "    ])\n",
    "\n",
    "    # 找出有 final_overlap 的行\n",
    "    rows_with_overlap = df_debug.filter(pl.col(\"final_overlap\") == 1).select([\n",
    "        \"anon_slr_id\", \"anon_byr_id\", \"row_in_group\"\n",
    "    ])\n",
    "\n",
    "    # 加上前後 buffer 區間\n",
    "    buffered_rows = rows_with_overlap.with_columns([\n",
    "        (pl.col(\"row_in_group\") - buffer).alias(\"start_row\"),\n",
    "        (pl.col(\"row_in_group\") + buffer).alias(\"end_row\")\n",
    "    ])\n",
    "\n",
    "    # 抓出前後 buffer 內的紀錄\n",
    "    df_to_check = (\n",
    "        df_debug.join(\n",
    "            buffered_rows,\n",
    "            on=[\"anon_slr_id\", \"anon_byr_id\"],\n",
    "            how=\"inner\"\n",
    "        )\n",
    "        .filter(\n",
    "            (pl.col(\"row_in_group\") >= pl.col(\"start_row\")) &\n",
    "            (pl.col(\"row_in_group\") <= pl.col(\"end_row\"))\n",
    "        )\n",
    "        .select([\n",
    "            \"anon_slr_id\", \"anon_byr_id\", \"anon_item_id\",\n",
    "            \"row_in_group\", \"src_cre_date\", \"prev_time\",\n",
    "            \"time_diff_seconds\", \"item_changed\",\n",
    "            \"overlap\", \"next_overlap\", \"final_overlap\"\n",
    "        ])\n",
    "        .unique()  # ✅ 去除重複筆數\n",
    "        .sort([\"anon_slr_id\", \"anon_byr_id\", \"row_in_group\"])\n",
    "    )\n",
    "\n",
    "    return df_to_check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChenChun\\AppData\\Local\\Temp\\ipykernel_8336\\577357169.py:14: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.arange(0, pl.count()).over([\"anon_slr_id\", \"anon_byr_id\"]).alias(\"row_in_group\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (20, 11)\n",
      "┌────────────┬───────────┬───────────┬───────────┬───┬───────────┬─────────┬───────────┬───────────┐\n",
      "│ anon_slr_i ┆ anon_byr_ ┆ anon_item ┆ row_in_gr ┆ … ┆ item_chan ┆ overlap ┆ next_over ┆ final_ove │\n",
      "│ d          ┆ id        ┆ _id       ┆ oup       ┆   ┆ ged       ┆ ---     ┆ lap       ┆ rlap      │\n",
      "│ ---        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ i32     ┆ ---       ┆ ---       │\n",
      "│ i64        ┆ i64       ┆ i64       ┆ i64       ┆   ┆ bool      ┆         ┆ i32       ┆ i32       │\n",
      "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═════════╪═══════════╪═══════════╡\n",
      "│ 89         ┆ 589814    ┆ 54955850  ┆ 0         ┆ … ┆ null      ┆ 0       ┆ 1         ┆ 1         │\n",
      "│ 89         ┆ 589814    ┆ 24454497  ┆ 1         ┆ … ┆ true      ┆ 1       ┆ 0         ┆ 1         │\n",
      "│ 89         ┆ 589814    ┆ 24454497  ┆ 2         ┆ … ┆ false     ┆ 0       ┆ 0         ┆ 0         │\n",
      "│ 140        ┆ 4470202   ┆ 64190767  ┆ 0         ┆ … ┆ null      ┆ 0       ┆ 1         ┆ 1         │\n",
      "│ 140        ┆ 4470202   ┆ 62939840  ┆ 1         ┆ … ┆ true      ┆ 1       ┆ 1         ┆ 1         │\n",
      "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …       ┆ …         ┆ …         │\n",
      "│ 140        ┆ 6494981   ┆ 16313882  ┆ 1         ┆ … ┆ false     ┆ 0       ┆ 1         ┆ 1         │\n",
      "│ 140        ┆ 6494981   ┆ 63139623  ┆ 2         ┆ … ┆ true      ┆ 1       ┆ 1         ┆ 1         │\n",
      "│ 140        ┆ 6494981   ┆ 59692910  ┆ 3         ┆ … ┆ true      ┆ 1       ┆ 0         ┆ 1         │\n",
      "│ 140        ┆ 6494981   ┆ 59692910  ┆ 4         ┆ … ┆ false     ┆ 0       ┆ 1         ┆ 1         │\n",
      "│ 140        ┆ 6494981   ┆ 63139623  ┆ 5         ┆ … ┆ true      ┆ 1       ┆ 0         ┆ 1         │\n",
      "└────────────┴───────────┴───────────┴───────────┴───┴───────────┴─────────┴───────────┴───────────┘\n",
      "被移除的小組數量（item 數）：4067197\n",
      "曾在短期內參與過不同 item 交易的 slr/byr 對數量：1228464\n",
      "檔案已儲存於 filtered_records.csv，共保留 40824367 筆\n",
      "已移除違規資料筆數：6537079 筆\n"
     ]
    }
   ],
   "source": [
    "from polars.datatypes import Struct, List\n",
    "\n",
    "# Step 1: 排序並計算相鄰紀錄差異\n",
    "\"\"\"\n",
    "第一步驟 : \n",
    "    每個 (slr_id, byr_id) 的紀錄會根據 src_cre_date 升冪排列（早→晚）\n",
    "第二步驟 :\n",
    "    針對每組 slr/byr 抓取：\n",
    "    上一筆的 src_cre_date → prev_time\n",
    "    上一筆的 item_id → prev_item\n",
    "第三步驟 :\n",
    "    標註兩筆之間是否為短時間內換商品 : \n",
    "    這裡是抓出與前一筆相差幾秒（若同一 slr/byr）\n",
    "    然後標記 item_id 是否不同 → item_changed\n",
    "第四步驟 :\n",
    "    定義 overlap 條件 : \n",
    "    48 * 3600 是 48 小時\n",
    "    在 48 小時內出現 不同商品 的紀錄，就標記為 \n",
    "    .shift(1) 的設計下  overlap 會「滯後標記」，只在pair 的後一筆被標記為 overlap\n",
    "\"\"\"\n",
    "df_sorted = (\n",
    "    # 第一步驟\n",
    "    df_filled_final.sort([\"anon_slr_id\", \"anon_byr_id\", \"src_cre_date\"]) \n",
    "    # 第二步驟\n",
    "    .with_columns([\n",
    "        pl.col(\"src_cre_date\").shift(1).over([\"anon_slr_id\", \"anon_byr_id\"]).alias(\"prev_time\"),\n",
    "        pl.col(\"anon_item_id\").shift(1).over([\"anon_slr_id\", \"anon_byr_id\"]).alias(\"prev_item\"),\n",
    "    ])\n",
    "    # 第三步驟\n",
    "    .with_columns([\n",
    "        (pl.col(\"src_cre_date\") - pl.col(\"prev_time\")).dt.total_seconds().alias(\"time_diff_seconds\"),\n",
    "        (pl.col(\"anon_item_id\") != pl.col(\"prev_item\")).alias(\"item_changed\")\n",
    "    ])\n",
    "    # 第四步驟\n",
    "    .with_columns([\n",
    "        pl.when(\n",
    "            (pl.col(\"time_diff_seconds\") <= 48 * 3600) & pl.col(\"item_changed\")\n",
    "        ).then(1).otherwise(0).alias(\"overlap\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "# 驗證: 只有每組的第一筆，prev_time 才應該是 null ===============================\n",
    "# df_checked = df_sorted.with_columns([\n",
    "#     pl.arange(0, pl.count()).over([\"anon_slr_id\", \"anon_byr_id\"]).alias(\"row_in_group\")\n",
    "# ])\n",
    "# invalid_nulls = df_checked.filter(\n",
    "#     (pl.col(\"row_in_group\") > 0) & (pl.col(\"prev_time\").is_null())\n",
    "# )\n",
    "# print(\"非第一筆但 prev_time 為 null 的異常筆數：\", invalid_nulls.height)\n",
    "# if invalid_nulls.height > 0:\n",
    "#     print(invalid_nulls.select([\n",
    "#         \"anon_slr_id\", \"anon_byr_id\", \"src_cre_date\", \"row_in_group\", \"prev_time\"\n",
    "#     ]).limit(5))\n",
    "# else:\n",
    "#     print(\"✅驗證成功：只有每組的第一筆 prev_time 才為 null\")\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: 標註相鄰也可能 overlap 的紀錄\n",
    "# 補回漏標的 overlap pair 前一筆 (被標記 overlap 的前一筆也應該是 overlap)\n",
    "df_overlap = df_sorted.with_columns([\n",
    "    pl.col(\"overlap\").shift(-1).over([\"anon_slr_id\", \"anon_byr_id\"]).fill_null(0).alias(\"next_overlap\")\n",
    "]).with_columns([\n",
    "    (pl.col(\"overlap\") | pl.col(\"next_overlap\")).alias(\"final_overlap\")\n",
    "])\n",
    "\n",
    "# 驗證: 抓出「包含 overlap 附近的資料段落」 =====================\n",
    "debug_result = debug_overlap_window(df_overlap)# 顯示 overlap 周圍前後 1 筆（預設值）\n",
    "print(debug_result.limit(20))# 印出前 20 筆檢查\n",
    "# =============================================================\n",
    "\n",
    "# Step 3: 找出有 overlap 的小組 (slr/byr/item)\n",
    "# 最終結果是：所有出現 overlap 的「(賣家、買家、商品) 組合」\n",
    "overlap_items = (\n",
    "    df_overlap.filter(pl.col(\"final_overlap\") == 1)\n",
    "    .select([\"anon_slr_id\", \"anon_byr_id\", \"anon_item_id\"])\n",
    "    .unique()\n",
    ")\n",
    "print(f\"被移除的小組數量（item 數）：{overlap_items.height}\")\n",
    "print(f\"曾在短期內參與過不同 item 交易的 slr/byr 對數量：{overlap_items.select(['anon_slr_id', 'anon_byr_id']).unique().height}\")\n",
    "\n",
    "# Step 4: 從原始資料中移除這些小組\n",
    "original_count = df_overlap.height  # 原始筆數\n",
    "df_final = df_overlap.join(overlap_items, on=[\"anon_slr_id\", \"anon_byr_id\", \"anon_item_id\"], how=\"anti\")\n",
    "removed_count = original_count - df_final.height  # 計算移除筆數\n",
    "\n",
    "\n",
    "# 匯出處理後的資料\n",
    "df_final.write_csv(\"data/filtered_records.csv\")\n",
    "\n",
    "# 印出處理資訊\n",
    "print(f\"檔案已儲存於 filtered_records.csv，共保留 {df_final.height} 筆\")\n",
    "print(f\"已移除違規資料筆數：{removed_count} 筆\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 反驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 時間差異接近48小時邊界的案例 ====\n",
      "shape: (10, 7)\n",
      "┌─────────────┬─────────────┬──────────────┬───────────────┬──────────────┬──────────────┬─────────┐\n",
      "│ anon_slr_id ┆ anon_byr_id ┆ anon_item_id ┆ src_cre_date  ┆ prev_time    ┆ time_diff_se ┆ overlap │\n",
      "│ ---         ┆ ---         ┆ ---          ┆ ---           ┆ ---          ┆ conds        ┆ ---     │\n",
      "│ i64         ┆ i64         ┆ i64          ┆ datetime[μs]  ┆ datetime[μs] ┆ ---          ┆ i32     │\n",
      "│             ┆             ┆              ┆               ┆              ┆ i64          ┆         │\n",
      "╞═════════════╪═════════════╪══════════════╪═══════════════╪══════════════╪══════════════╪═════════╡\n",
      "│ 3054028     ┆ 9693622     ┆ 63475063     ┆ 2013-05-03    ┆ 2013-05-01   ┆ 169201       ┆ 1       │\n",
      "│             ┆             ┆              ┆ 11:41:01      ┆ 12:41:00     ┆              ┆         │\n",
      "│ 3622812     ┆ 6354757     ┆ 81113427     ┆ 2013-02-11    ┆ 2013-02-09   ┆ 169201       ┆ 1       │\n",
      "│             ┆             ┆              ┆ 07:35:24      ┆ 08:35:23     ┆              ┆         │\n",
      "│ 5791599     ┆ 1926244     ┆ 83071534     ┆ 2012-12-18    ┆ 2012-12-16   ┆ 169201       ┆ 1       │\n",
      "│             ┆             ┆              ┆ 14:36:42      ┆ 15:36:41     ┆              ┆         │\n",
      "│ 6439241     ┆ 5659        ┆ 30968039     ┆ 2012-07-05    ┆ 2012-07-03   ┆ 169201       ┆ 1       │\n",
      "│             ┆             ┆              ┆ 19:15:42      ┆ 20:15:41     ┆              ┆         │\n",
      "│ 192639      ┆ 9315560     ┆ 7358180      ┆ 2012-10-19    ┆ 2012-10-17   ┆ 169202       ┆ 1       │\n",
      "│             ┆             ┆              ┆ 16:26:27      ┆ 17:26:25     ┆              ┆         │\n",
      "│ 205946      ┆ 6284138     ┆ 57368921     ┆ 2013-07-31    ┆ 2013-07-29   ┆ 169202       ┆ 1       │\n",
      "│             ┆             ┆              ┆ 19:40:00      ┆ 20:39:58     ┆              ┆         │\n",
      "│ 1638155     ┆ 3474997     ┆ 81408220     ┆ 2013-07-02    ┆ 2013-06-30   ┆ 169202       ┆ 1       │\n",
      "│             ┆             ┆              ┆ 00:03:30      ┆ 01:03:28     ┆              ┆         │\n",
      "│ 5849984     ┆ 5630465     ┆ 81706379     ┆ 2012-12-05    ┆ 2012-12-03   ┆ 169202       ┆ 1       │\n",
      "│             ┆             ┆              ┆ 00:37:58      ┆ 01:37:56     ┆              ┆         │\n",
      "│ 8898692     ┆ 4892811     ┆ 58360494     ┆ 2012-11-23    ┆ 2012-11-21   ┆ 169202       ┆ 1       │\n",
      "│             ┆             ┆              ┆ 13:40:30      ┆ 14:40:28     ┆              ┆         │\n",
      "│ 6581954     ┆ 4114246     ┆ 60248004     ┆ 2013-07-02    ┆ 2013-06-30   ┆ 169203       ┆ 1       │\n",
      "│             ┆             ┆              ┆ 11:55:54      ┆ 12:55:51     ┆              ┆         │\n",
      "└─────────────┴─────────────┴──────────────┴───────────────┴──────────────┴──────────────┴─────────┘\n",
      "==== 時間差異統計 ====\n",
      "shape: (1, 3)\n",
      "┌────────────────┬────────────────┬────────────────┐\n",
      "│ 最小時間差(秒) ┆ 最大時間差(秒) ┆ 平均時間差(秒) │\n",
      "│ ---            ┆ ---            ┆ ---            │\n",
      "│ i64            ┆ i64            ┆ f64            │\n",
      "╞════════════════╪════════════════╪════════════════╡\n",
      "│ 0              ┆ 49454459       ┆ 1.3614e6       │\n",
      "└────────────────┴────────────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# 找出時間差異接近48小時邊界的案例\n",
    "boundary_cases = df_sorted.filter(\n",
    "    (pl.col(\"time_diff_seconds\").is_not_null()) & \n",
    "    (pl.col(\"time_diff_seconds\") > 48 * 3600 - 3600) & \n",
    "    (pl.col(\"time_diff_seconds\") < 48 * 3600 + 3600) &\n",
    "    (pl.col(\"item_changed\"))\n",
    ").select([\n",
    "    \"anon_slr_id\", \"anon_byr_id\", \"anon_item_id\", \n",
    "    \"src_cre_date\", \"prev_time\", \"time_diff_seconds\",\n",
    "    \"overlap\"\n",
    "]).sort(\"time_diff_seconds\")\n",
    "\n",
    "print(\"==== 時間差異接近48小時邊界的案例 ====\")\n",
    "print(boundary_cases.limit(10))\n",
    "\n",
    "# 檢視時間差異的統計信息\n",
    "time_diff_summary = df_sorted.filter(\n",
    "    pl.col(\"time_diff_seconds\").is_not_null() & pl.col(\"item_changed\")\n",
    ").select([\n",
    "    pl.min(\"time_diff_seconds\").alias(\"最小時間差(秒)\"),\n",
    "    pl.max(\"time_diff_seconds\").alias(\"最大時間差(秒)\"),\n",
    "    pl.mean(\"time_diff_seconds\").alias(\"平均時間差(秒)\")\n",
    "])\n",
    "\n",
    "print(\"==== 時間差異統計 ====\")\n",
    "print(time_diff_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_cleaned 處理空值\n",
    "any_mssg、'fdbk_score_src', 'fdbk_pstv_src' 若為空值，補 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40824367, 24)\n",
      "欄位有缺失值：['fdbk_score_src', 'fdbk_pstv_src', 'any_mssg', 'prev_time', 'prev_item', 'time_diff_seconds', 'item_changed']\n",
      "['anon_item_id', 'anon_thread_id', 'anon_byr_id', 'anon_slr_id', 'src_cre_dt', 'fdbk_score_src', 'fdbk_pstv_src', 'offr_type_id', 'status_id', 'offr_price', 'src_cre_date', 'response_time', 'slr_hist', 'byr_hist', 'any_mssg', 'byr_us', 'row_num', 'prev_time', 'prev_item', 'time_diff_seconds', 'item_changed', 'overlap', 'next_overlap', 'final_overlap']\n",
      "['anon_item_id', 'anon_thread_id', 'anon_byr_id', 'anon_slr_id', 'src_cre_dt', 'fdbk_score_src', 'fdbk_pstv_src', 'offr_type_id', 'status_id', 'offr_price', 'src_cre_date', 'response_time', 'slr_hist', 'byr_hist', 'any_mssg', 'byr_us', 'row_num']\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "df_final = pl.read_csv('data/filtered_records.csv')\n",
    "print(df_final.shape)\n",
    "\n",
    "null_counts = df_final.null_count()\n",
    "cols_with_nulls = [col for col, count in zip(null_counts.columns, null_counts.row(0)) if count != 0]\n",
    "print(f\"欄位有缺失值：{cols_with_nulls}\")\n",
    "\n",
    "print(df_final.columns)\n",
    "df_final = df_final.drop(['prev_time', 'prev_item', 'time_diff_seconds', 'item_changed', 'overlap', 'next_overlap', 'final_overlap'])\n",
    "print(df_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9, 4)\n",
      "┌────────────┬─────────────┬────────────────┬───────────────┐\n",
      "│ statistic  ┆ any_mssg    ┆ fdbk_score_src ┆ fdbk_pstv_src │\n",
      "│ ---        ┆ ---         ┆ ---            ┆ ---           │\n",
      "│ str        ┆ f64         ┆ f64            ┆ f64           │\n",
      "╞════════════╪═════════════╪════════════════╪═══════════════╡\n",
      "│ count      ┆ 4.0824367e7 ┆ 4.0824367e7    ┆ 4.0824367e7   │\n",
      "│ null_count ┆ 0.0         ┆ 0.0            ┆ 0.0           │\n",
      "│ mean       ┆ 0.135966    ┆ 6221.791541    ┆ 99.120297     │\n",
      "│ std        ┆ 0.342753    ┆ 22789.566126   ┆ 7.368475      │\n",
      "│ min        ┆ 0.0         ┆ -2.0           ┆ 0.0           │\n",
      "│ 25%        ┆ 0.0         ┆ 302.0          ┆ 99.6          │\n",
      "│ 50%        ┆ 0.0         ┆ 1223.0         ┆ 99.85         │\n",
      "│ 75%        ┆ 0.0         ┆ 4451.0         ┆ 100.0         │\n",
      "│ max        ┆ 1.0         ┆ 2.299731e6     ┆ 100.0         │\n",
      "└────────────┴─────────────┴────────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 將指定欄位的空值補為 0\n",
    "df_final = df_final.with_columns([\n",
    "    pl.col('any_mssg').fill_null(0),\n",
    "    pl.col('fdbk_score_src').fill_null(0),\n",
    "    pl.col('fdbk_pstv_src').fill_null(0)\n",
    "])\n",
    "\n",
    "# 查看更新後的結果\n",
    "print(df_final.select(['any_mssg', 'fdbk_score_src', 'fdbk_pstv_src']).describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 刪除 status_id ==6 or status_id ==9 的資料\n",
    "- 不能直接刪掉!!! 要判斷 offer_type_id == 0 時，才可刪除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 操作一：offr_type_id == 0 且 status_id in [6, 9] (自動接受/刪除)=====\n",
      "觸發筆數: 8753678，整組刪除: 10006674，剩餘: 30817693\n",
      "\n",
      "===== 操作二：status_id in [1, 2, 8] 且 src_cre_date == response_time =====\n",
      "觸發筆數: 264，整組刪除: 300，剩餘: 30817393\n",
      "\n",
      "===== 操作三：src_cre_date > response_time =====\n",
      "觸發筆數: 727，整組刪除: 911，剩餘: 30816482\n"
     ]
    }
   ],
   "source": [
    "# df_final 已是 Polars DataFrame\n",
    "pl_df = df_final.with_columns(\n",
    "    pl.concat_str([\"anon_item_id\", \"anon_thread_id\", \"anon_byr_id\", \"anon_slr_id\"], separator=\"_\").alias(\"group_key\")\n",
    ")\n",
    "\n",
    "\n",
    "### ===== 操作一：offr_type_id == 0 且 status_id in [6, 9] =====\n",
    "original_count = pl_df.height\n",
    "\n",
    "trigger_rows = pl_df.filter(\n",
    "    (pl.col(\"offr_type_id\") == 0) & (pl.col(\"status_id\").is_in([6, 9]))\n",
    ")\n",
    "trigger_count = trigger_rows.height\n",
    "\n",
    "keys_to_delete = trigger_rows.select(\"group_key\").unique().to_series().to_list()\n",
    "\n",
    "pl_df = pl_df.filter(~pl.col(\"group_key\").is_in(keys_to_delete))\n",
    "new_count = pl_df.height\n",
    "deleted_count = original_count - new_count\n",
    "\n",
    "\n",
    "print(f\"===== 操作一：offr_type_id == 0 且 status_id in [6, 9] (自動接受/刪除)=====\")\n",
    "print(f\"觸發筆數: {trigger_count}，整組刪除: {deleted_count}，剩餘: {new_count}\\n\")\n",
    "\n",
    "### ===== 操作二：status_id in [1, 2, 8] 且 src_cre_date == response_time =====\n",
    "original_count = pl_df.height\n",
    "\n",
    "trigger_rows = pl_df.filter(\n",
    "    (pl.col(\"status_id\").is_in([1, 2, 8])) & (pl.col(\"src_cre_date\") == pl.col(\"response_time\"))\n",
    ")\n",
    "trigger_count = trigger_rows.height\n",
    "\n",
    "keys_to_delete = trigger_rows.select(\"group_key\").unique().to_series().to_list()\n",
    "\n",
    "pl_df = pl_df.filter(~pl.col(\"group_key\").is_in(keys_to_delete))\n",
    "new_count = pl_df.height\n",
    "deleted_count = original_count - new_count\n",
    "\n",
    "print(f\"===== 操作二：status_id in [1, 2, 8] 且 src_cre_date == response_time =====\")\n",
    "print(f\"觸發筆數: {trigger_count}，整組刪除: {deleted_count}，剩餘: {new_count}\\n\")\n",
    "\n",
    "### ===== 操作三：src_cre_date > response_time =====\n",
    "original_count = pl_df.height\n",
    "\n",
    "trigger_rows = pl_df.filter(\n",
    "    pl.col(\"src_cre_date\") > pl.col(\"response_time\")\n",
    ")\n",
    "trigger_count = trigger_rows.height\n",
    "\n",
    "keys_to_delete = trigger_rows.select(\"group_key\").unique().to_series().to_list()\n",
    "\n",
    "pl_df = pl_df.filter(~pl.col(\"group_key\").is_in(keys_to_delete))\n",
    "new_count = pl_df.height\n",
    "deleted_count = original_count - new_count\n",
    "\n",
    "print(f\"===== 操作三：src_cre_date > response_time =====\")\n",
    "print(f\"觸發筆數: {trigger_count}，整組刪除: {deleted_count}，剩餘: {new_count}\")\n",
    "\n",
    "### 最後移除輔助欄位\n",
    "pl_df = pl_df.drop(\"group_key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 篩選 round 1 和 round 2 的資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 0320 改成: 第一輪就結束的資料才屬於round1 ； 只有兩輪的資料才屬於round2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 資料以此四個欄位分群: [\"anon_item_id\", \"anon_slr_id\", \"anon_thread_id\", \"anon_byr_id\"]  並依 src_cre_date 排序 \n",
    "2. 篩選組內僅有 offr_type_id == 0 的資料，這些資料存入 r1_df \n",
    "3. 接著在剩餘的資料中，篩選每一群中 最後一個offr_type_id == 0 (前面已使用src_cre_date排序)的資料的下一筆(offr_type_id != 0) ，若是此資料只有一筆offr_type_id != 0接續在組內最後一筆offr_type_id == 0 之後，則將最後一個 0 的那筆以及下一筆非0 存入 r2_df<br>\n",
    "*註: 若 組內最後一筆offr_type_id == 0 之後有大於一筆offr_type_id != 0 即**不能 存入 r2_df**\n",
    "*註: 最後一筆 0 跟第一筆非 0 之前的所有資料 → 它們才是我們要存進 r2_df 的！\n",
    "    範例資料: \n",
    "    ```\n",
    "    group\tsrc_cre_date\toffr_type_id\trow_number\n",
    "    A\t    2024-01-01\t    0\t    \t    0\n",
    "    A\t    2024-01-02\t    0\t    \t    1\n",
    "    A\t    2024-01-03\t    1\t   \t      2\n",
    "    # 這三筆都應該存進 r2_df ，但先前我們山除了自動接受跟拒絕，\n",
    "    # 因此這種屬於例外，應查看有幾筆 (也就是r2_df 中有幾組group 是超過2筆資料的)\n",
    "    ```\n",
    "\n",
    "4. 顯示r1_df, r2_df 各有幾筆資料，及沒有被分入r1_df, r2_df 的pl_df 剩下的有幾筆資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChenChun\\AppData\\Local\\Temp\\ipykernel_8336\\1339240898.py:127: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  r2_group_counts = r2_df.group_by(group_cols).count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1_df 筆數（整組都是 0）: 12108565\n",
      "r2_df 筆數（0 接 1 筆非 0）: 10621366\n",
      "未分類剩餘筆數（不屬於 r1/r2）: 8086551\n",
      "=====\n",
      "原始輸入資料與此步驟分組資料筆數加總是否正確: 1\n",
      "【例外情況】其中筆數超過兩筆的 group 數量: 0\n",
      "已成功匯出 r1_df (clean_thread_r1.csv)與 r2_df (clean_thread_r2.csv) 為 CSV 檔案\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 分組依據的欄位\n",
    "group_cols = [\"anon_item_id\", \"anon_slr_id\", \"anon_thread_id\", \"anon_byr_id\"]\n",
    "\n",
    "# Step 1: 先根據分組欄位與日期欄位進行排序(組內排序)\n",
    "pl_df = pl_df.sort(group_cols + [\"src_cre_date\"])\n",
    "\n",
    "# Step 2: 找出每組中只包含 offr_type_id == 0 的群組\n",
    "# 方法：計算每組中 offr_type_id 的最大值\n",
    "type_stats = (\n",
    "    pl_df\n",
    "    .group_by(group_cols)\n",
    "    .agg([\n",
    "        pl.col(\"offr_type_id\").max().alias(\"max_type_id\"),\n",
    "        pl.col(\"offr_type_id\").min().alias(\"min_type_id\"),\n",
    "        pl.len().alias(\"count_rows\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "# 找出整組都是 0 的群組條件：max == 0 且 min == 0 ， 得到一張「只有 group key 的 DataFrame」\n",
    "only_zero_groups = type_stats.filter(\n",
    "    (pl.col(\"max_type_id\") == 0) & (pl.col(\"min_type_id\") == 0)\n",
    ").select(group_cols)\n",
    "\n",
    "# 用 join 方式篩選這些群組的資料 → r1_df\n",
    "r1_df = pl_df.join(only_zero_groups, on=group_cols, how=\"inner\")\n",
    "\n",
    "# Step 3: 剩下的資料 = 非純 0 的群組\n",
    "remaining_df = pl_df.join(only_zero_groups, on=group_cols, how=\"anti\") # anti 會跟 inner互補\n",
    "\n",
    "# Step 3-1: 為了進一步處理，我們為每筆資料加上該群內的 row number\n",
    "# 方便後面定位特定位置\n",
    "remaining_with_rownum = (\n",
    "    remaining_df\n",
    "    .with_columns([\n",
    "        pl.col(\"offr_type_id\").alias(\"original_type\"),  # 保留原始 type 資訊\n",
    "        pl.arange(0, pl.len()).over(group_cols).alias(\"row_number\"),\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Step 3-2: 抓出每組中最後一筆 offr_type_id == 0 的 row_number\n",
    "last_zero_index = (\n",
    "    remaining_with_rownum\n",
    "    .filter(pl.col(\"original_type\") == 0)\n",
    "    .group_by(group_cols)\n",
    "    .agg(pl.col(\"row_number\").max().alias(\"last_zero_row\"))\n",
    ")\n",
    "\n",
    "# ====================== 補充檢查 =========================\n",
    "# 檢查 group 中「第一筆為 type != 0」後，是否仍出現過 type == 0\n",
    "# 印出違反此規則的資料筆數 : (若沒有違反則不會print]違反則不會print])\n",
    "\n",
    "# Step A: 先找出每組第一筆資料的 row（row_number == 0）\n",
    "first_row_type = (\n",
    "    remaining_with_rownum\n",
    "    .filter(pl.col(\"row_number\") == 0)\n",
    "    .with_columns([\n",
    "        pl.col(\"original_type\").alias(\"first_type\")\n",
    "    ])\n",
    "    .select(group_cols + [\"first_type\"])\n",
    ")\n",
    "\n",
    "# Step B: 找出那些 first_type != 0 的 group\n",
    "first_type_nonzero = first_row_type.filter(pl.col(\"first_type\") != 0)\n",
    "\n",
    "# Step C: 再從原始資料中找這些 group 是否還有其他 type == 0 的資料\n",
    "# （但不要算 row_number == 0，那是第一筆，已經驗證過不是 0）\n",
    "potential_violations = (\n",
    "    remaining_with_rownum\n",
    "    .join(first_type_nonzero, on=group_cols, how=\"inner\")\n",
    "    .filter((pl.col(\"row_number\") > 0) & (pl.col(\"original_type\") == 0))\n",
    ")\n",
    "\n",
    "# 若違規筆數大於 0，才印出提醒\n",
    "violation_count = potential_violations.shape[0]\n",
    "if violation_count > 0:\n",
    "    print(f\"⚠️ 發現違反規則的資料筆數：{violation_count}\")\n",
    "    # 若你想看是哪幾組 group，也可以印出 unique groups：\n",
    "    # print(potential_violations.select(group_cols).unique())\n",
    "# =========================================================\n",
    "\n",
    "# Step 3-2.5: 每組內，row_number > last_zero_row 的第一筆非 0\n",
    "# 先合併 last_zero_row，然後篩選條件\n",
    "post_last_zero = remaining_with_rownum.join(last_zero_index, on=group_cols, how=\"inner\")\n",
    "first_nonzero_after_last_zero = (\n",
    "    post_last_zero\n",
    "    .filter((pl.col(\"original_type\") != 0) & (pl.col(\"row_number\") > pl.col(\"last_zero_row\")))\n",
    "    .group_by(group_cols)\n",
    "    .agg(pl.col(\"row_number\").min().alias(\"first_nonzero_row\"))\n",
    ")\n",
    "\n",
    "# 替代原本的 first_nonzero_index 與 join\n",
    "range_limits = last_zero_index.join(first_nonzero_after_last_zero, on=group_cols, how=\"inner\")\n",
    "\n",
    "\n",
    "# 加入原資料\n",
    "df_with_range = remaining_with_rownum.join(range_limits, on=group_cols, how=\"left\")\n",
    "\n",
    "# 抓出 row_number 在範圍內的資料\n",
    "df_next_to_zero = df_with_range.filter(\n",
    "    (pl.col(\"row_number\") <= pl.col(\"first_nonzero_row\")) &\n",
    "    (pl.col(\"row_number\") >= pl.col(\"last_zero_row\"))\n",
    ")\n",
    "\n",
    "# Step 3-4: 確保 first_nonzero_row 剛好是最後一個非 0（才符合只接一筆非 0）\n",
    "# 也就是在每組裡面，last_zero_row 後面不能有第二筆非 0\n",
    "post_zero_nonzero_counts = (\n",
    "    remaining_with_rownum\n",
    "    .join(last_zero_index, on=group_cols, how=\"inner\")\n",
    "    .filter(\n",
    "        (pl.col(\"row_number\") > pl.col(\"last_zero_row\")) &\n",
    "        (pl.col(\"original_type\") != 0)\n",
    "    )\n",
    "    .group_by(group_cols)\n",
    "    .agg(pl.len().alias(\"nonzero_after_zero\"))\n",
    ")\n",
    "\n",
    "# 篩選符合條件的 group（最後一筆 0 後面只有一筆非 0）\n",
    "valid_r2_groups = post_zero_nonzero_counts.filter(\n",
    "    pl.col(\"nonzero_after_zero\") == 1\n",
    ").select(group_cols)\n",
    "\n",
    "# 取得符合條件的 r2_df\n",
    "r2_df = df_next_to_zero.join(valid_r2_groups, on=group_cols, how=\"inner\") \\\n",
    "                       .drop([\"row_number\", \"last_zero_row\", \"first_nonzero_row\", \"original_type\"])\n",
    "\n",
    "# 額外統計：r2_df 中有幾組 group 是超過兩筆資料\n",
    "r2_group_counts = r2_df.group_by(group_cols).count()\n",
    "r2_more_than_2 = r2_group_counts.filter(pl.col(\"count\") > 2).shape[0]\n",
    "\n",
    "\n",
    "# Step 4: 計算剩餘資料（從 pl_df 中扣掉 r1_df + r2_df）\n",
    "# 為了比較是否為重複資料，使用全部欄位進行 anti join\n",
    "used_rows = pl.concat([r1_df, r2_df])\n",
    "remaining_final = pl_df.join(used_rows, on=pl_df.columns, how=\"anti\")\n",
    "\n",
    "# 顯示結果\n",
    "print(f\"r1_df 筆數（整組都是 0）: {r1_df.shape[0]}\")\n",
    "print(f\"r2_df 筆數（0 接 1 筆非 0）: {r2_df.shape[0]}\")\n",
    "print(f\"未分類剩餘筆數（不屬於 r1/r2）: {remaining_final.shape[0]}\")\n",
    "print(\"=====\")\n",
    "print(f\"原始輸入資料與此步驟分組資料筆數加總是否正確: { 1 if pl_df.shape[0]== r1_df.shape[0]+r2_df.shape[0]+remaining_final.shape[0] else 0}\")\n",
    "print(f\"【例外情況】其中筆數超過兩筆的 group 數量: {r2_more_than_2}\")\n",
    "\n",
    "# 存成 CSV 檔案\n",
    "r1_df.write_csv(\"data/clean_thread_r1.csv\")\n",
    "r2_df.write_csv(\"data/clean_thread_r2.csv\")\n",
    "\n",
    "print(\"已成功匯出 r1_df (clean_thread_r1.csv)與 r2_df (clean_thread_r2.csv) 為 CSV 檔案\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 驗證 : \n",
    "> 1. df1 與 df2 的組內皆沒有，用 src_cre_datec 排序後 ，第一筆中 offr_type_id 不是 0 的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "r1_df =pl.read_csv(\"data/clean_thread_r1.csv\")\n",
    "r2_df =pl.read_csv(\"data/clean_thread_r2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "r1_df 中第一筆資料中 offr_type_id ≠ 0 的 group 數量：0\n",
      "\n",
      "r2_df 中第一筆資料中 offr_type_id ≠ 0 的 group 數量：0\n"
     ]
    }
   ],
   "source": [
    "group_keys = [\"anon_slr_id\", \"anon_byr_id\", \"anon_item_id\", \"anon_thread_id\"]\n",
    "\n",
    "# Step 1：針對 df1 和 r2_df 分別處理\n",
    "for name, df in [(\"r1_df\", r1_df), (\"r2_df\", r2_df)]:\n",
    "    # 為每個 group 加上 group 排序順序（用 src_cre_date 排）\n",
    "    df_with_rank = (\n",
    "        df.sort(group_keys + [\"src_cre_date\"])\n",
    "        .with_columns([\n",
    "            pl.arange(0, pl.len()).over(group_keys).alias(\"row_num\")\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # 取每組第一筆\n",
    "    first_rows = df_with_rank.filter(pl.col(\"row_num\") == 0)\n",
    "\n",
    "    # 檢查第一筆中 offr_type_id != 0 的異常資料\n",
    "    invalid_first = first_rows.filter(pl.col(\"offr_type_id\") != 0)\n",
    "\n",
    "    # 顯示結果\n",
    "    print(f\"\\n{name} 中第一筆資料中 offr_type_id ≠ 0 的 group 數量：{invalid_first.height}\")\n",
    "    if invalid_first.height > 0:\n",
    "        print(invalid_first.select(group_keys + [\"src_cre_date\", \"offr_type_id\"]).limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join \n",
    "- 此步驟要將已整理好的 clean_thread_r1.csv 及 clean_thread_r2.csv --(left join)--> clean_anon_bo_lists.csv\n",
    "- 依據 anon_item_id 與 anon_slr_id 進行 inner join\n",
    "- 結果輸入變數 merged_r1_df 及 merged_r2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1_df 筆數: 12108565 merged_r1_df 筆數: 12072061\n",
      "r2_df 筆數: 10621366 merged_r2_df 筆數: 10607882\n"
     ]
    }
   ],
   "source": [
    "# 載入主資料表（被 join 的左表）\n",
    "bo_df = pl.read_csv(r\"C:\\Users\\ChenChun\\Downloads\\bargaining_data\\clean_anon_bo_lists.csv\")\n",
    "\n",
    "# 指定 join key\n",
    "join_keys = [\"anon_item_id\", \"anon_slr_id\"]\n",
    "\n",
    "# 執行 inner join\n",
    "merged_r1_df = r1_df.join(bo_df, on=join_keys, how=\"inner\")\n",
    "merged_r2_df = r2_df.join(bo_df, on=join_keys, how=\"inner\")\n",
    "\n",
    "# 顯示合併後的資料筆數與型態\n",
    "print(\"r1_df 筆數:\", r1_df.height,\"merged_r1_df 筆數:\", merged_r1_df.height)\n",
    "print(\"r2_df 筆數:\", r2_df.height,\"merged_r2_df 筆數:\", merged_r2_df.height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join 後的資料清理\n",
    "join 完成後，須根據以下條件清理資料:\n",
    "  0. L1：排除 start_price_usd > 1000\n",
    "  0. L2 : clean_list.csv 已事先完成\n",
    "  1. T1 所有出價( offr_price )需低於刊登價格，也就是**（offr_price <= start_price_usd）**，若違反此規則\n",
    "  2. ~~T2：賣家和買家均不可超過三次出價~~\n",
    "  3. T3 若備標註為反向出價的資料( status_id == 7 )，必須有對應反價數據 (需要有下一筆資料)\n",
    "  4. T4 被接受的報價( status_id == 0 or 6 )，不得有後續報價 \n",
    "  5. T5 移除重複記錄\n",
    "\n",
    "  最終輸出：只保留 不違反 T1 ~ T5 的**群組**，(若有一筆資料違反，則整組group key 一同刪除)\n",
    "\n",
    "> 註: 之前清理 bo_lists 的條件:\n",
    "> 1. 'anon_item_id', 'anon_slr_id' 皆不為空\n",
    "> 2. ( 參考 L2 ) 若商品售出( item_price != N/A)，售價( item_price )不得大於商品列表的標價( start_price_usd )\n",
    "> 3. 捨棄參考標價欄位(count …)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_merged_offer_df(df: pl.DataFrame, label=\"\") -> pl.DataFrame:\n",
    "    group_cols = [\"anon_item_id\", \"anon_slr_id\", \"anon_thread_id\", \"anon_byr_id\"]\n",
    "    \n",
    "    # ========== Step L1：排除 start_price_usd > 1000 的群組 ==========\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"start_price_usd\") > 1000).fill_null(False).alias(\"L1_flag\")\n",
    "    ])\n",
    "\n",
    "    # 抓出有違規的群組\n",
    "    l1_violation_groups = (\n",
    "        df.filter(pl.col(\"L1_flag\") == True)\n",
    "        .select(group_cols)\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    if l1_violation_groups.height > 0:\n",
    "        affected = df.join(l1_violation_groups, on=group_cols, how=\"semi\").shape[0]\n",
    "        print(f\"🚫 {label} L1 限制：移除 start_price_usd > 1000 的群組，共刪除 {affected} 筆\")\n",
    "        df = df.join(l1_violation_groups, on=group_cols, how=\"anti\")\n",
    "\n",
    "    df = df.drop(\"L1_flag\")  # 清理暫存欄位\n",
    "    \n",
    "    # ========== 資料排序 ==========\n",
    "    df = df.sort(group_cols + [\"src_cre_date\"])\n",
    "    \n",
    "    # ========== Step T1：offr_price 不得高於 start_price_usd ==========\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"offr_price\") > pl.col(\"start_price_usd\")).fill_null(False).alias(\"T1_flag\")\n",
    "    ])\n",
    "\n",
    "    # 統計 T1 違規 group\n",
    "    group_stats = (\n",
    "        df.group_by(group_cols)\n",
    "        .agg([\n",
    "            pl.col(\"T1_flag\").any().alias(\"T1_flag\"),\n",
    "            pl.count().alias(\"group_size\"),\n",
    "            pl.sum(\"T1_flag\").alias(\"T1_individual\"),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    t1_stats = group_stats.filter(pl.col(\"T1_flag\") == True)\n",
    "    t1_individual_removed = t1_stats.select(pl.sum(\"T1_individual\")).item() if t1_stats.height > 0 else 0\n",
    "    t1_group_total_removed = t1_stats.select(pl.sum(\"group_size\")).item() if t1_stats.height > 0 else 0\n",
    "    t1_group_removed = t1_group_total_removed - t1_individual_removed\n",
    "\n",
    "    if t1_group_total_removed > 0:\n",
    "        print(f\"🚫 {label} T1 限制：刪除了 {t1_individual_removed} 筆資料，連帶刪除群組資料 {t1_group_removed} 筆，共刪除 {t1_group_total_removed} 筆\")\n",
    "\n",
    "    # 移除 T1 違規 group\n",
    "    t1_bad_groups = t1_stats.select(group_cols)\n",
    "    df = df.join(t1_bad_groups, on=group_cols, how=\"anti\")\n",
    "    \n",
    "    # ========== Step T3：若某筆 status_id == 7，則該筆不能是 group 最後一筆 ==========\n",
    "    # 為每筆資料加上 row_number 與 group_size\n",
    "    df = df.sort(group_cols + [\"src_cre_date\"]).with_columns([\n",
    "        pl.len().over(group_cols).alias(\"group_size\"),\n",
    "        pl.arange(0, pl.len()).over(group_cols).alias(\"row_number\")\n",
    "    ])\n",
    "\n",
    "    # 找出 status_id == 7 且是 group 最後一筆的資料\n",
    "    t3_violation_rows = df.filter(\n",
    "        (pl.col(\"status_id\") == 7) &\n",
    "        (pl.col(\"row_number\") == pl.col(\"group_size\") - 1)\n",
    "    )\n",
    "\n",
    "    # 擷取這些違規資料所屬 group\n",
    "    t3_violation_groups = t3_violation_rows.select(group_cols).unique()\n",
    "\n",
    "    # 從原始 df 移除整個 group\n",
    "    if t3_violation_groups.height > 0:\n",
    "        affected = df.join(t3_violation_groups, on=group_cols, how=\"semi\").shape[0]\n",
    "        print(f\"🚫 {label} T3 限制：移除最後一筆為 status_id==7 的群組，共刪除 {affected} 筆\")\n",
    "        df = df.join(t3_violation_groups, on=group_cols, how=\"anti\")\n",
    "\n",
    "\n",
    "\n",
    "    # ========== Step T4：若 group 中 status_id == 0/6 被接受，後面不得再出價 ==========\n",
    "    df = df.sort(group_cols + [\"src_cre_date\"]).with_columns(\n",
    "        pl.arange(0, pl.len()).over(group_cols).alias(\"row_number\")\n",
    "    )\n",
    "\n",
    "    accepted = (\n",
    "        df.filter(pl.col(\"status_id\").is_in([0, 6]))\n",
    "        .group_by(group_cols)\n",
    "        .agg(pl.col(\"row_number\").min().alias(\"accept_row\"))\n",
    "    )\n",
    "\n",
    "    df_accept = df.join(accepted, on=group_cols, how=\"left\")\n",
    "\n",
    "    # 找出接受後仍出價的 group\n",
    "    post_accepted_groups = (\n",
    "        df_accept\n",
    "        .filter(\n",
    "            pl.col(\"row_number\") > pl.col(\"accept_row\")\n",
    "        )\n",
    "        .select(group_cols)\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    if post_accepted_groups.height > 0:\n",
    "        affected = df_accept.join(post_accepted_groups, on=group_cols, how=\"semi\").shape[0]\n",
    "        print(f\"🚫 {label} T4 限制：移除接受後仍出價的群組，共刪除 {affected} 筆\")\n",
    "        df_accept = df_accept.join(post_accepted_groups, on=group_cols, how=\"anti\")\n",
    "\n",
    "    df = df_accept.drop([\"row_number\", \"accept_row\"])\n",
    "\n",
    "    # ========== Step T5：移除重複 ==========\n",
    "    before = df.height\n",
    "    df = df.unique()\n",
    "    after = df.height\n",
    "    if after < before:\n",
    "        print(f\"ℹ️ {label} T5：移除重複記錄 {before - after} 筆\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚫 R1 L1 限制：移除 start_price_usd > 1000 的群組，共刪除 689691 筆\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChenChun\\AppData\\Local\\Temp\\ipykernel_8336\\2734003073.py:36: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias(\"group_size\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚫 R1 T1 限制：刪除了 38160 筆資料，連帶刪除群組資料 3495 筆，共刪除 41655 筆\n",
      "🚫 R1 T3 限制：移除最後一筆為 status_id==7 的群組，共刪除 346 筆\n",
      "🚫 R1 T4 限制：移除接受後仍出價的群組，共刪除 346325 筆\n",
      "🚫 R2 L1 限制：移除 start_price_usd > 1000 的群組，共刪除 730904 筆\n",
      "🚫 R2 T1 限制：刪除了 251340 筆資料，連帶刪除群組資料 197564 筆，共刪除 448904 筆\n",
      "🚫 R2 T3 限制：移除最後一筆為 status_id==7 的群組，共刪除 164 筆\n",
      "🚫 R2 T4 限制：移除接受後仍出價的群組，共刪除 4636 筆\n"
     ]
    }
   ],
   "source": [
    "cleaned_r1_df = clean_merged_offer_df(merged_r1_df, label=\"R1\")\n",
    "cleaned_r2_df = clean_merged_offer_df(merged_r2_df, label=\"R2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 檢查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列出 R1 中 group_size 不等於 1 的資料: 822368\n",
      "R2 中 group_size 不等於 2 的資料  : 0\n"
     ]
    }
   ],
   "source": [
    "# 檢查 R1 中 group_size 不等於 1 的資料\n",
    "r1_invalid = cleaned_r1_df.filter(pl.col(\"group_size\") != 1)\n",
    "print(f\"列出 R1 中 group_size 不等於 1 的資料: {r1_invalid.height}\")\n",
    "# 列出 R1 中 group_size 不等於 1 的資料\n",
    "# print(r1_invalid.select([\"anon_item_id\", \"anon_slr_id\", \"anon_thread_id\", \"anon_byr_id\", \"group_size\"]))\n",
    "\n",
    "# 檢查 R2 中 group_size 不等於 2 的資料  \n",
    "r2_invalid = cleaned_r2_df.filter(pl.col(\"group_size\") != 2)\n",
    "print(f\"R2 中 group_size 不等於 2 的資料  : {r2_invalid.height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "刪去多於欄位並儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10994044\n",
      "9423274\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned_r1_df))\n",
    "print(len(cleaned_r2_df))\n",
    "cleaned_r1_df = cleaned_r1_df.drop(['T1_flag','group_size'])\n",
    "cleaned_r2_df = cleaned_r2_df.drop(['T1_flag','group_size'])\n",
    "# 可選擇匯出結果\n",
    "cleaned_r1_df.write_csv(\"data/cleaned_r1_joined.csv\")\n",
    "cleaned_r2_df.write_csv(\"data/cleaned_r2_joined.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 處理\n",
    "> 0415 改成: SRP_0是原始商品標價\n",
    "\n",
    "1. round1 (cleaned_r1_joined.csv): 每組都僅一列資料\n",
    "    需要新增的欄位:\n",
    "    - BRP_0: 買家初報價\n",
    "    - SRT_0: 賣家回覆時間(單位:秒)\n",
    "    - SRP_0: 賣家價格\n",
    "    - SA_0: 賣家是否同意(0/1)\n",
    "\n",
    "2. round2 (cleaned_r1_joined.csv):  每組有兩列資料\n",
    "    - type 1. 賣家拒絕，並反報價\n",
    "        需要新增的欄位:\n",
    "        - 第一筆：BRP_0, SRT_0\n",
    "        - 第二筆 :  SRP_1,BRT_1,BA_1\n",
    "\n",
    "    - type 2. 賣家僅拒絕，沒有反報價，買家二次報價\n",
    "        需要新增的欄位:\n",
    "        - 第一筆 :  BRP_0, SRT_0\n",
    "        - 第二筆 :  BRT_1, BRP_1, SRT_2  ,SA_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. round1 (cleaned_r1_joined.csv): 每組都僅一列資料\n",
    "- 新建立一個欄位 `BRP_0` :\n",
    "    - BRP_0 = `start_price_usd` 減去 `offr_price`\n",
    "\n",
    "- 新欄位 `SRT_0`(單位:秒) : \n",
    "    - status_id == 0 (報價過期)，SRT_0 為 48 小時\n",
    "    - ~~status_id == 7 (反報價)，則 SRT_0 為下一筆資料的`src_cre_date` 減去 此筆資料的`src_cre_date`~~\n",
    "    - status_id 為  1,2,8 (接受/拒絕/其他買家被接受) ，SRT_0 為此筆資料 (`response_time - src_cre_date`)\n",
    "    - ~~status_id 為  6,9 ，SRT_0 為 0~~\n",
    "\n",
    "- 新欄位`SA_0`(Seller Acceptance): \n",
    "    - status_id == 0,2,6,7,8 ，此欄位為 0 \n",
    "    - status_id == 1,9 ，此欄位為 1 \n",
    "  \n",
    "- 新欄位`SRP_0`:\n",
    "    - 商品初始價格 `start_price_usd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# 載入 Round1 資料\n",
    "df = pl.read_csv(\"data/cleaned_r1_joined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round1_done.csv 已完成並匯出\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = df.with_columns([\n",
    "    pl.col(\"src_cre_date\").str.strptime(pl.Datetime, strict=False),\n",
    "    pl.col(\"response_time\").str.strptime(pl.Datetime, strict=False),\n",
    "])\n",
    "\n",
    "# 加入 BRP_0 欄位\n",
    "df = df.with_columns([\n",
    "    (pl.col(\"start_price_usd\") - pl.col(\"offr_price\")).alias(\"BRP_0\")\n",
    "])\n",
    "\n",
    "# 加入 SRT_0：根據 status_id 決定秒數\n",
    "df = df.with_columns([\n",
    "    pl.when(pl.col(\"status_id\") == 0)\n",
    "      .then(48 * 3600)\n",
    "      .when(pl.col(\"status_id\").is_in([1, 2, 8]))\n",
    "      .then(\n",
    "          ((pl.col(\"response_time\") - pl.col(\"src_cre_date\"))\n",
    "           .dt.total_nanoseconds() / 1_000_000_000).cast(pl.Int32)\n",
    "      )\n",
    "      .otherwise(None)  # 更合理地回傳 Null，而不是 0\n",
    "      .alias(\"SRT_0\")\n",
    "])\n",
    "\n",
    "\n",
    "# 加入 SA_0\n",
    "df = df.with_columns([\n",
    "    pl.when(pl.col(\"status_id\").is_in([1, 9]))\n",
    "      .then(1)\n",
    "      .otherwise(0)\n",
    "      .alias(\"SA_0\")\n",
    "])\n",
    "\n",
    "# 加入 SRP_0\n",
    "df = df.with_columns([\n",
    "    pl.col(\"start_price_usd\").alias(\"SRP_0\")\n",
    "])\n",
    "\n",
    "# 匯出處理結果\n",
    "df.write_csv(\"data/round1_done.csv\")\n",
    "print(\"round1_done.csv 已完成並匯出\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 檢查\n",
    "針對以下欄位做檢查：\n",
    "\n",
    "| 欄位    | 合理性檢查說明 |\n",
    "|---------|----------------|\n",
    "| `BRP_0` | 不應為極端大值（如 > 1000）、不應大量為 null |\n",
    "| `SRP_0` | 應該與 \"start_price_usd\" 相同\n",
    "| `SA_0`  | 應該同時有 0 與 1，若只有一種值 → 不合理 |\n",
    "| `SRT_0` | 通常應該 >= 60 秒，若出現大量 < 1 秒或負值 → 不合理 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= BRP_0 統計:\n",
      "最大 BRP: 999.01\n",
      "平均 BRP: 50.49\n",
      "shape: (1, 3)\n",
      "┌──────────┬───────────┬───────────┐\n",
      "│ null_BRP ┆ mean_BRP  ┆ std_BRP   │\n",
      "│ ---      ┆ ---       ┆ ---       │\n",
      "│ u32      ┆ f64       ┆ f64       │\n",
      "╞══════════╪═══════════╪═══════════╡\n",
      "│ 0        ┆ 50.494412 ┆ 93.525258 │\n",
      "└──────────┴───────────┴───────────┘\n",
      "\n",
      "========= SRP_0 確認:\n",
      "shape: (1, 3)\n",
      "┌────────────┬──────────────┬──────────────┐\n",
      "│ 相同值數量 ┆ 不相同值數量 ┆ 相同值百分比 │\n",
      "│ ---        ┆ ---          ┆ ---          │\n",
      "│ u32        ┆ u32          ┆ f64          │\n",
      "╞════════════╪══════════════╪══════════════╡\n",
      "│ 10994044   ┆ 0            ┆ 100.0        │\n",
      "└────────────┴──────────────┴──────────────┘\n",
      "\n",
      "========= SA_0 分布:\n",
      "shape: (1, 2)\n",
      "┌────────────┬───────────┐\n",
      "│ SA_0_zeros ┆ SA_0_ones │\n",
      "│ ---        ┆ ---       │\n",
      "│ u32        ┆ u32       │\n",
      "╞════════════╪═══════════╡\n",
      "│ 4749659    ┆ 6244385   │\n",
      "└────────────┴───────────┘\n",
      "\n",
      "========= SRT_0 分布:\n",
      "shape: (1, 5)\n",
      "┌─────────────┬───────────┬────────────────┬─────────┬──────────────┐\n",
      "│ SRT_0_lt_1s ┆ SRT_0_is0 ┆ SRT_0_negative ┆ max_SRT ┆ mean_SRT     │\n",
      "│ ---         ┆ ---       ┆ ---            ┆ ---     ┆ ---          │\n",
      "│ u32         ┆ u32       ┆ u32            ┆ i64     ┆ f64          │\n",
      "╞═════════════╪═══════════╪════════════════╪═════════╪══════════════╡\n",
      "│ 0           ┆ 0         ┆ 0              ┆ 336248  ┆ 37900.703436 │\n",
      "└─────────────┴───────────┴────────────────┴─────────┴──────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChenChun\\AppData\\Local\\Temp\\ipykernel_8336\\3465950016.py:17: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  (pl.count() - pl.sum(\"is_identical\")).alias(\"不相同值數量\"),\n",
      "C:\\Users\\ChenChun\\AppData\\Local\\Temp\\ipykernel_8336\\3465950016.py:18: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  (pl.sum(\"is_identical\") / pl.count() * 100).alias(\"相同值百分比\")\n"
     ]
    }
   ],
   "source": [
    "df = pl.read_csv(\"data/round1_done.csv\")\n",
    "\n",
    "# 1. 檢查 BRP_0 是否有超過 1000、是否大量為 null\n",
    "brp_stats = df.select([\n",
    "    pl.col(\"BRP_0\").null_count().alias(\"null_BRP\"),\n",
    "    pl.col(\"BRP_0\").mean().alias(\"mean_BRP\"),\n",
    "    pl.col(\"BRP_0\").std().alias(\"std_BRP\"),\n",
    "])\n",
    "\n",
    "# 2. 檢查 SRP_0 是否等於 start_price_usd\n",
    "identical_check = df.with_columns([\n",
    "    (pl.col(\"SRP_0\") == pl.col(\"start_price_usd\")).alias(\"is_identical\")\n",
    "])\n",
    "# 統計不同的情況\n",
    "identity_stats = identical_check.select([\n",
    "    pl.sum(\"is_identical\").alias(\"相同值數量\"),\n",
    "    (pl.count() - pl.sum(\"is_identical\")).alias(\"不相同值數量\"),\n",
    "    (pl.sum(\"is_identical\") / pl.count() * 100).alias(\"相同值百分比\")\n",
    "])\n",
    "\n",
    "# 3. 檢查 SA_0 是否只有 0 或 1\n",
    "sa_stats = df.select([\n",
    "    (pl.col(\"SA_0\") == 0).sum().alias(\"SA_0_zeros\"),\n",
    "    (pl.col(\"SA_0\") == 1).sum().alias(\"SA_0_ones\"),\n",
    "])\n",
    "\n",
    "# 4. 檢查 SRT_0 是否有過短（<1秒）或為負值\n",
    "srt_stats = df.select([\n",
    "    (pl.col(\"SRT_0\") < 1).sum().alias(\"SRT_0_lt_1s\"),\n",
    "    (pl.col(\"SRT_0\") == 0).sum().alias(\"SRT_0_is0\"),\n",
    "    (pl.col(\"SRT_0\") < 0).sum().alias(\"SRT_0_negative\"),\n",
    "    pl.col(\"SRT_0\").max().alias(\"max_SRT\"),\n",
    "    pl.col(\"SRT_0\").mean().alias(\"mean_SRT\")\n",
    "])\n",
    "\n",
    "print(\"========= BRP_0 統計:\")\n",
    "stats = df.select([\n",
    "    pl.col(\"BRP_0\").max().alias(\"max_BRP\"),\n",
    "    pl.col(\"BRP_0\").mean().alias(\"mean_BRP\")\n",
    "]).to_dicts()[0]\n",
    "\n",
    "print(f\"最大 BRP: {stats['max_BRP']:.2f}\")\n",
    "print(f\"平均 BRP: {stats['mean_BRP']:.2f}\")\n",
    "print(brp_stats)\n",
    "\n",
    "print(\"\\n========= SRP_0 確認:\")\n",
    "print(identity_stats)\n",
    "\n",
    "print(\"\\n========= SA_0 分布:\")\n",
    "print(sa_stats)\n",
    "\n",
    "print(\"\\n========= SRT_0 分布:\")\n",
    "print(srt_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 檢查SRT_0 > 48小時的紀錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChenChun\\AppData\\Local\\Temp\\ipykernel_8336\\1696487933.py:9: ChronoFormatWarning: Detected the pattern `.%f` in the chrono format string. This pattern should not be used to parse values after a decimal point. Use `%.f` instead. See the full specification: https://docs.rs/chrono/latest/chrono/format/strftime\n",
      "  pl.col(\"src_cre_date\").str.strptime(pl.Datetime, format=\"%Y-%m-%dT%H:%M:%S.%f\").alias(\"src_cre_date\"),\n",
      "C:\\Users\\ChenChun\\AppData\\Local\\Temp\\ipykernel_8336\\1696487933.py:10: ChronoFormatWarning: Detected the pattern `.%f` in the chrono format string. This pattern should not be used to parse values after a decimal point. Use `%.f` instead. See the full specification: https://docs.rs/chrono/latest/chrono/format/strftime\n",
      "  pl.col(\"response_time\").filter(pl.col(\"response_time\").is_not_null())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRT_0 超過 48 小時 (172800 秒) 的記錄數: 1182\n",
      "\n",
      "異常資料樣本:\n",
      "shape: (10, 5)\n",
      "┌────────┬────────────────┬─────────────┬─────────────┬──────────────┐\n",
      "│ SRT_0  ┆ anon_thread_id ┆ anon_slr_id ┆ anon_byr_id ┆ anon_item_id │\n",
      "│ ---    ┆ ---            ┆ ---         ┆ ---         ┆ ---          │\n",
      "│ i64    ┆ i64            ┆ i64         ┆ i64         ┆ i64          │\n",
      "╞════════╪════════════════╪═════════════╪═════════════╪══════════════╡\n",
      "│ 336248 ┆ 7387830        ┆ 2226650     ┆ 602076      ┆ 68328749     │\n",
      "│ 332313 ┆ 10951974       ┆ 5435235     ┆ 5711358     ┆ 8671325      │\n",
      "│ 329145 ┆ 4672182        ┆ 625801      ┆ 9761812     ┆ 94027845     │\n",
      "│ 329125 ┆ 1033529        ┆ 1311544     ┆ 9742284     ┆ 86879973     │\n",
      "│ 322731 ┆ 11831385       ┆ 1206777     ┆ 2912888     ┆ 56970751     │\n",
      "│ 322485 ┆ 12098952       ┆ 2359264     ┆ 6186306     ┆ 55750189     │\n",
      "│ 317500 ┆ 2567275        ┆ 5070189     ┆ 6641468     ┆ 50015835     │\n",
      "│ 310125 ┆ 3265650        ┆ 4106421     ┆ 228889      ┆ 35203219     │\n",
      "│ 309058 ┆ 1144430        ┆ 5298742     ┆ 4145115     ┆ 93802166     │\n",
      "│ 308638 ┆ 12824370       ┆ 1469871     ┆ 638498      ┆ 31120531     │\n",
      "└────────┴────────────────┴─────────────┴─────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# 檢查 SRT_0 > 172800 (48小時) 的資料\n",
    "abnormal_srt = df.filter(pl.col(\"SRT_0\") > 172800)\n",
    "\n",
    "# 顯示異常資料的筆數\n",
    "print(f\"SRT_0 超過 48 小時 (172800 秒) 的記錄數: {abnormal_srt.height}\")\n",
    "\n",
    "# 使用正確的ISO格式進行轉換\n",
    "df = df.with_columns([\n",
    "    pl.col(\"src_cre_date\").str.strptime(pl.Datetime, format=\"%Y-%m-%dT%H:%M:%S.%f\").alias(\"src_cre_date\"),\n",
    "    pl.col(\"response_time\").filter(pl.col(\"response_time\").is_not_null())\n",
    "      .str.strptime(pl.Datetime, format=\"%Y-%m-%dT%H:%M:%S.%f\").alias(\"response_time\")\n",
    "])\n",
    "\n",
    "# 轉換後，顯示異常記錄的詳細信息\n",
    "abnormal_srt = df.filter(pl.col(\"SRT_0\") > 172800)\n",
    "if abnormal_srt.height > 0:\n",
    "    print(\"\\n異常資料樣本:\")\n",
    "    # 選擇可用的欄位\n",
    "    available_cols = [col for col in [\"SRT_0\", \"anon_thread_id\", \"anon_slr_id\", \"anon_byr_id\", \"anon_item_id\"] \n",
    "                     if col in abnormal_srt.columns]\n",
    "    \n",
    "    print(abnormal_srt.select(available_cols).sort(\"SRT_0\", descending=True).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. round2 (cleaned_r1_joined.csv):  每組有兩列資料\n",
    "\n",
    "1. type 1. 賣家拒絕，並反報價 ( 群組第二筆資料的 offr_type_id == 2 )\n",
    "    需要新增的欄位:\n",
    "    - 第一筆：BRP_0, SRT_0, SRP_0\n",
    "      - `BRP` :`start_price_usd` 減去 `offr_price`\n",
    "      - `SRT`(單位:秒) : \n",
    "          - status_id == 0 (報價過期)，SRT_0 為 48 小時\n",
    "          - status_id == 7 (反報價)，則 SRT_0 為下一筆資料的`src_cre_date` 減去 此筆資料的`src_cre_date`\n",
    "          - status_id 為  1,2,8 (接受/拒絕/其他買家被接受) ，SRT_0 為此筆資料 (`response_time - src_cre_date`)\n",
    "          - ~~status_id 為  6,9 ，SRT_0 為 0~~\n",
    "      - `SRP_0`:`start_price_usd`\n",
    "    - 第二筆 :  SRP_1,BRT_1,BA_1\n",
    "      - `SRP`: `start_price_usd` 減去 `offr_price`\n",
    "      - `BRT`(單位:秒) : \n",
    "          - status_id == 0 (報價過期)，SRT_0 為 48 小時\n",
    "          - ~~status_id == 7 (反報價)，則 SRT_0 為下一筆資料的`src_cre_date` 減去 此筆資料的`src_cre_date`~~\n",
    "          - status_id 為  1,2,8 (接受/拒絕/其他買家被接受) ，SRT_0 為此筆資料 (`response_time - src_cre_date`)\n",
    "          - ~~status_id 為  6,9 ，SRT_0 為 0~~\n",
    "      - `BA` :\n",
    "        - status_id == 0,2,6,7,8 (拒絕)，此欄位為 0 \n",
    "        - status_id == 1,9 (接受)，此欄位為 1 \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "2. type 2. 賣家僅拒絕，沒有反報價，買家二次報價 ( 群組第二筆資料的 offr_type_id == 1 )\n",
    "    需要新增的欄位:\n",
    "    - 第一筆 :  BRP_0, SRT_0, SRP_0\n",
    "      - `BRP` :`start_price_usd` 減去 `offr_price`\n",
    "      - `SRT`(單位:秒) : \n",
    "          - status_id == 0 (報價過期)，SRT_0 為 48 小時\n",
    "          - status_id == 7 (反報價)，則 SRT_0 為下一筆資料的`src_cre_date` 減去 此筆資料的`src_cre_date`\n",
    "          - status_id 為  1,2,8 (接受/拒絕/其他買家被接受) ，SRT_0 為此筆資料 (`response_time - src_cre_date`)\n",
    "          - ~~status_id 為  6,9 ，SRT_0 為 0~~\n",
    "      - `SRP_0`:`start_price_usd`\n",
    "    - 第二筆 :  BRT_1, BRP_1, SRT_2  ,SA_1 \n",
    "      - `BRT`(單位:秒) :此筆資料的`src_cre_date` 減去 上一筆資料的`response_time`\n",
    "      - `BRP` :`start_price_usd` 減去 `offr_price`\n",
    "      - `SRT`(單位:秒) : \n",
    "          - status_id == 0 (報價過期)，SRT_0 為 48 小時\n",
    "          - ~~status_id == 7 (反報價)，則 SRT_0 為下一筆資料的`src_cre_date` 減去 此筆資料的`src_cre_date`~~\n",
    "          - status_id 為  1,2,8 (接受/拒絕/其他買家被接受) ，SRT_0 為此筆資料 (`response_time - src_cre_date`)\n",
    "          - ~~status_id 為  6,9 ，SRT_0 為 0~~\n",
    "      - `SA` :\n",
    "        - status_id == 0,2,6,7,8 (拒絕)，此欄位為 0 \n",
    "        - status_id == 1,9 (接受)，此欄位為 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 1 資料筆數: 9423274\n",
      "Type 2 資料筆數: 0\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# 載入 Round1 資料\n",
    "df = pl.read_csv(\"data/cleaned_r2_joined.csv\")\n",
    "\n",
    "df.select([\n",
    "    pl.col(\"start_price_usd\").null_count().alias(\"null_start_price_usd\"),\n",
    "    pl.col(\"offr_price\").null_count().alias(\"null_offr_price\")\n",
    "])\n",
    "\n",
    "\n",
    "df = df.with_columns([\n",
    "    pl.col(\"src_cre_date\").str.strptime(pl.Datetime, strict=False),\n",
    "    pl.col(\"response_time\").str.strptime(pl.Datetime, strict=False),\n",
    "])\n",
    "\n",
    "# 定義分組欄位並排序（組內依時間）\n",
    "group_cols = [\"anon_item_id\", \"anon_slr_id\", \"anon_thread_id\", \"anon_byr_id\"]\n",
    "df = df.sort(group_cols + [\"src_cre_date\"])\n",
    "\n",
    "# 加上 group_index（組內排序）\n",
    "df = df.with_columns([\n",
    "    pl.arange(0, pl.len()).over(group_cols).alias(\"group_index\")\n",
    "])\n",
    "\n",
    "# 將第二筆的 offr_type_id 抓出來當群組分類依據\n",
    "group_type_df = (\n",
    "    df.filter(pl.col(\"group_index\") == 1)\n",
    "    .select(group_cols + [pl.col(\"offr_type_id\").alias(\"second_offr_type_id\")])\n",
    ")\n",
    "df = df.join(group_type_df, on=group_cols, how=\"left\")\n",
    "\n",
    "# 分出 type1 和 type2\n",
    "type1_df = df.filter(pl.col(\"second_offr_type_id\") == 2)\n",
    "type2_df = df.filter(pl.col(\"second_offr_type_id\") == 1)\n",
    "\n",
    "# 印出 type1_df 與 type2_df的資料筆數\n",
    "print(f\"Type 1 資料筆數: {type1_df.shape[0]}\")\n",
    "print(f\"Type 2 資料筆數: {type2_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round2_type1.csv 已輸出\n"
     ]
    }
   ],
   "source": [
    "type1_df = type1_df.with_columns([\n",
    "    pl.col(\"src_cre_date\").shift(-1).over(group_cols).alias(\"next_src_cre_date\")\n",
    "])\n",
    "\n",
    "\n",
    "# 定義 SRT 計算函式\n",
    "def compute_srt(status_col, response_col, src_col, next_src_col):\n",
    "    return (\n",
    "        pl.when(status_col == 0)\n",
    "        .then(48 * 3600)\n",
    "        .when(status_col == 7)\n",
    "        .then(((next_src_col - src_col).dt.total_nanoseconds() / 1_000_000_000).cast(pl.Int32))\n",
    "        .when(status_col.is_in([1, 2, 8]))\n",
    "        .then(((response_col - src_col).dt.total_nanoseconds() / 1_000_000_000).cast(pl.Int32))\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "\n",
    "# ➤ Type 1 處理\n",
    "type1 = type1_df.with_columns([\n",
    "    # 第一筆\n",
    "    pl.when(pl.col(\"group_index\") == 0)\n",
    "      .then(pl.col(\"start_price_usd\") - pl.col(\"offr_price\"))\n",
    "      .otherwise(None)\n",
    "      .alias(\"BRP_0\"),\n",
    "\n",
    "    pl.when(pl.col(\"group_index\") == 0)\n",
    "    .then(compute_srt(\n",
    "        pl.col(\"status_id\"),\n",
    "        pl.col(\"response_time\"),\n",
    "        pl.col(\"src_cre_date\"),\n",
    "        pl.col(\"next_src_cre_date\")\n",
    "    ))\n",
    "    .otherwise(None)\n",
    "    .alias(\"SRT_0\"),\n",
    "    \n",
    "    pl.when(pl.col(\"group_index\") == 0)\n",
    "    .then(pl.col(\"start_price_usd\"))\n",
    "    .otherwise(None)  # 明確處理其他情況\n",
    "    .alias(\"SRP_0\"),\n",
    "\n",
    "    # 第二筆\n",
    "    pl.when(pl.col(\"group_index\") == 1)\n",
    "      .then(pl.col(\"start_price_usd\") - pl.col(\"offr_price\"))\n",
    "      .otherwise(None)\n",
    "      .alias(\"SRP_1\"),\n",
    "\n",
    "    pl.when(pl.col(\"group_index\") == 1)\n",
    "    .then(compute_srt(\n",
    "        pl.col(\"status_id\"),\n",
    "        pl.col(\"response_time\"),\n",
    "        pl.col(\"src_cre_date\"),\n",
    "        pl.col(\"next_src_cre_date\")\n",
    "    ))\n",
    "    .otherwise(None)\n",
    "    .alias(\"BRT_1\"),\n",
    "\n",
    "\n",
    "    pl.when(pl.col(\"group_index\") == 1)\n",
    "      .then(pl.when(pl.col(\"status_id\").is_in([1, 9])).then(1).otherwise(0))\n",
    "      .otherwise(None)\n",
    "      .alias(\"BA_1\"),\n",
    "])\n",
    "\n",
    "\n",
    "# # ➤ Type 2 處理（需要加入前一筆 response_time）\n",
    "# # 先新增前一筆 response_time\n",
    "# type2_df = type2_df.with_columns([\n",
    "#     pl.col(\"response_time\")\n",
    "#       .shift(1)\n",
    "#       .over(group_cols)\n",
    "#       .alias(\"prev_response_time\")\n",
    "# ])\n",
    "\n",
    "# type2 = type2_df.with_columns([\n",
    "#     # 第一筆\n",
    "#     pl.when(pl.col(\"group_index\") == 0)\n",
    "#       .then(pl.col(\"start_price_usd\") - pl.col(\"offr_price\"))\n",
    "#       .otherwise(None)\n",
    "#       .alias(\"BRP_0\"),\n",
    "\n",
    "#     pl.when(pl.col(\"group_index\") == 0)\n",
    "#       .then(compute_srt(pl.col(\"status_id\"), pl.col(\"response_time\"), pl.col(\"src_cre_date\")))\n",
    "#       .otherwise(None)\n",
    "#       .alias(\"SRT_0\"),\n",
    "\n",
    "#     # 第二筆\n",
    "#     pl.when(pl.col(\"group_index\") == 1)\n",
    "#       .then(((pl.col(\"src_cre_date\") - pl.col(\"prev_response_time\")).dt.total_nanoseconds() / 1_000_000_000).cast(pl.Int32))\n",
    "#       .otherwise(None)\n",
    "#       .alias(\"BRT_1\"),\n",
    "\n",
    "#     pl.when(pl.col(\"group_index\") == 1)\n",
    "#       .then(pl.col(\"start_price_usd\") - pl.col(\"offr_price\"))\n",
    "#       .otherwise(None)\n",
    "#       .alias(\"BRP_1\"),\n",
    "\n",
    "#     pl.when(pl.col(\"group_index\") == 1)\n",
    "#       .then(compute_srt(pl.col(\"status_id\"), pl.col(\"response_time\"), pl.col(\"src_cre_date\")))\n",
    "#       .otherwise(None)\n",
    "#       .alias(\"SRT_2\"),\n",
    "\n",
    "#     pl.when(pl.col(\"group_index\") == 1)\n",
    "#       .then(pl.when(pl.col(\"status_id\").is_in([1, 9])).then(1).otherwise(0))\n",
    "#       .otherwise(None)\n",
    "#       .alias(\"SA_1\"),\n",
    "# ])\n",
    "\n",
    "\n",
    "# 合併輸出結果（可視需要寫成 csv）\n",
    "# 匯出 Type1 資料\n",
    "type1.write_csv(\"data/round2_type1.csv\")\n",
    "print(\"round2_type1.csv 已輸出\")\n",
    "\n",
    "# # 匯出 Type2 資料\n",
    "# type2.write_csv(\"round2_type2.csv\")\n",
    "# print(\"round2_type2.csv 已輸出\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 檢查個欄位合理性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總資料筆數:  9423274\n",
      "每組有兩筆資料，一半欄位應該為 Null，4711637*2= 9423274\n",
      "\n",
      "📊 合理性檢查 - Type 1\n",
      "🔍 欄位 BRP_0 - Null 數量: 4711637\n",
      "🔍 欄位 SRT_0 - Null 數量: 4711637\n",
      "🔍 欄位 SRP_1 - Null 數量: 4711637\n",
      "🔍 欄位 BRT_1 - Null 數量: 4711637\n",
      "🔍 欄位 BA_1 - Null 數量: 4711637\n",
      "⚠️ 欄位 SRT_0 有 0 筆小於 1 秒的資料\n",
      "⚠️ 欄位 BRT_1 有 0 筆小於 1 秒的資料\n",
      "\n",
      "✅ 欄位 BA_1 數值分布:\n",
      "shape: (3, 2)\n",
      "┌──────┬─────────┐\n",
      "│ BA_1 ┆ count   │\n",
      "│ ---  ┆ ---     │\n",
      "│ i64  ┆ u32     │\n",
      "╞══════╪═════════╡\n",
      "│ null ┆ 4711637 │\n",
      "│ 0    ┆ 3649768 │\n",
      "│ 1    ┆ 1061869 │\n",
      "└──────┴─────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChenChun\\AppData\\Local\\Temp\\ipykernel_8336\\1278563784.py:30: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  print(df.group_by(col).count().sort(col))\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# 讀取資料\n",
    "type1_df = pl.read_csv(\"data/round2_type1.csv\")\n",
    "\n",
    "print(\"總資料筆數: \",len(type1_df))\n",
    "print(\"每組有兩筆資料，一半欄位應該為 Null，4711637*2=\",4711637*2)\n",
    "# 檢查欄位是否缺值\n",
    "def check_columns(df, label, expected_cols):\n",
    "    print(f\"\\n📊 合理性檢查 - {label}\")\n",
    "    for col in expected_cols:\n",
    "        if col in df.columns:\n",
    "            null_count = df.filter(pl.col(col).is_null()).shape[0]\n",
    "            print(f\"🔍 欄位 {col} - Null 數量: {null_count}\")\n",
    "        else:\n",
    "            print(f\"⚠️ 欄位 {col} 缺失！\")\n",
    "\n",
    "# 檢查是否秒數過短（小於1秒）\n",
    "def check_duration_issues(df, label, duration_cols):\n",
    "    for col in duration_cols:\n",
    "        if col in df.columns:\n",
    "            too_fast = df.filter(pl.col(col) < 1).shape[0]\n",
    "            print(f\"⚠️ 欄位 {col} 有 {too_fast} 筆小於 1 秒的資料\")\n",
    "\n",
    "# 檢查 0/1 分布\n",
    "def check_binary_distribution(df, label, binary_cols):\n",
    "    for col in binary_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n✅ 欄位 {col} 數值分布:\")\n",
    "            print(df.group_by(col).count().sort(col))\n",
    "\n",
    "# 預期欄位定義\n",
    "type1_cols = [\"BRP_0\", \"SRT_0\", \"SRP_1\", \"BRT_1\", \"BA_1\"]\n",
    "# type2_cols = [\"BRP_0\", \"SRT_0\", \"BRT_1\", \"BRP_1\", \"SRT_2\", \"SA_1\"]\n",
    "\n",
    "# 執行檢查\n",
    "check_columns(type1_df, \"Type 1\", type1_cols)\n",
    "# check_columns(type2_df, \"Type 2\", type2_cols)\n",
    "\n",
    "check_duration_issues(type1_df, \"Type 1\", [\"SRT_0\", \"BRT_1\"])\n",
    "# check_duration_issues(type2_df, \"Type 2\", [\"SRT_0\", \"BRT_1\", \"SRT_2\"])\n",
    "\n",
    "check_binary_distribution(type1_df, \"Type 1\", [\"BA_1\"])\n",
    "# check_binary_distribution(type2_df, \"Type 2\", [\"SA_1\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bargaining_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
